"""
æ€§èƒ½å¯¹æ¯”å·¥å…·
å¯¹æ¯”ä¸¤æ¬¡æµ‹è¯•ç»“æœï¼Œåˆ†ææ€§èƒ½å˜åŒ–
"""
import json
import sys
from pathlib import Path
from datetime import datetime


def load_report(file_path):
    """åŠ è½½æµ‹è¯•æŠ¥å‘Š"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½ {file_path}: {e}")
        return None


def compare_reports(baseline_path, current_path):
    """å¯¹æ¯”ä¸¤ä¸ªæµ‹è¯•æŠ¥å‘Š"""
    
    print("\n" + "=" * 80)
    print("  æ€§èƒ½å¯¹æ¯”åˆ†æ")
    print("=" * 80)
    print()
    
    # åŠ è½½æŠ¥å‘Š
    baseline = load_report(baseline_path)
    current = load_report(current_path)
    
    if not baseline or not current:
        print("âŒ æ— æ³•åŠ è½½æµ‹è¯•æŠ¥å‘Š")
        return
    
    print(f"åŸºçº¿æµ‹è¯•: {baseline_path}")
    print(f"å½“å‰æµ‹è¯•: {current_path}")
    print()
    
    baseline_results = baseline.get("results", {})
    current_results = current.get("results", {})
    
    # å¯¹æ¯”å„é¡¹æ€§èƒ½
    print("=" * 80)
    print("  æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
    print("=" * 80)
    print()
    
    # 1. å¹¶å‘å¤„ç†æ€§èƒ½
    if "concurrent_processing" in baseline_results and "concurrent_processing" in current_results:
        print("ğŸ“Š å¹¶å‘å¤„ç†æ€§èƒ½:")
        compare_concurrent_processing(
            baseline_results["concurrent_processing"],
            current_results["concurrent_processing"]
        )
        print()
    
    # 2. é˜Ÿåˆ—æ€§èƒ½
    if "queue_performance" in baseline_results and "queue_performance" in current_results:
        print("ğŸ“¦ é˜Ÿåˆ—æ€§èƒ½:")
        compare_queue_performance(
            baseline_results["queue_performance"],
            current_results["queue_performance"]
        )
        print()
    
    # 3. æ ¼å¼è½¬æ¢æ€§èƒ½
    if "message_formatting" in baseline_results and "message_formatting" in current_results:
        print("ğŸ”„ æ ¼å¼è½¬æ¢æ€§èƒ½:")
        compare_formatting_performance(
            baseline_results["message_formatting"],
            current_results["message_formatting"]
        )
        print()
    
    # 4. é™æµå™¨æ€§èƒ½
    if "rate_limiter" in baseline_results and "rate_limiter" in current_results:
        print("â±ï¸  é™æµå™¨å‡†ç¡®åº¦:")
        compare_rate_limiter(
            baseline_results["rate_limiter"],
            current_results["rate_limiter"]
        )
        print()
    
    # æ€»ç»“
    print("=" * 80)
    print("  æ€»ç»“")
    print("=" * 80)
    print()
    
    generate_summary(baseline_results, current_results)


def compare_concurrent_processing(baseline, current):
    """å¯¹æ¯”å¹¶å‘å¤„ç†æ€§èƒ½"""
    
    print("  å¹¶å‘çº§åˆ« | åŸºçº¿ååé‡ | å½“å‰ååé‡ | å˜åŒ– | çŠ¶æ€")
    print("  " + "-" * 70)
    
    for i, (base_item, curr_item) in enumerate(zip(baseline, current)):
        if base_item['concurrent'] != curr_item['concurrent']:
            continue
        
        concurrent = base_item['concurrent']
        base_throughput = base_item.get('throughput', 0)
        curr_throughput = curr_item.get('throughput', 0)
        
        change = ((curr_throughput - base_throughput) / base_throughput * 100) if base_throughput > 0 else 0
        status = get_performance_status(change)
        
        print(f"  {concurrent:^10} | {base_throughput:^12.2f} | {curr_throughput:^12.2f} | "
              f"{change:^6.1f}% | {status}")


def compare_queue_performance(baseline, current):
    """å¯¹æ¯”é˜Ÿåˆ—æ€§èƒ½"""
    
    print("  æ‰¹é‡å¤§å° | æŒ‡æ ‡ | åŸºçº¿QPS | å½“å‰QPS | å˜åŒ– | çŠ¶æ€")
    print("  " + "-" * 75)
    
    for base_item, curr_item in zip(baseline, current):
        if base_item['batch_size'] != curr_item['batch_size']:
            continue
        
        batch_size = base_item['batch_size']
        
        # å…¥é˜Ÿæ€§èƒ½
        base_enqueue = base_item.get('enqueue_qps', 0)
        curr_enqueue = curr_item.get('enqueue_qps', 0)
        change_enqueue = ((curr_enqueue - base_enqueue) / base_enqueue * 100) if base_enqueue > 0 else 0
        status_enqueue = get_performance_status(change_enqueue)
        
        print(f"  {batch_size:^9} | å…¥é˜Ÿ | {base_enqueue:^10.2f} | {curr_enqueue:^10.2f} | "
              f"{change_enqueue:^6.1f}% | {status_enqueue}")
        
        # å‡ºé˜Ÿæ€§èƒ½
        base_dequeue = base_item.get('dequeue_qps', 0)
        curr_dequeue = curr_item.get('dequeue_qps', 0)
        change_dequeue = ((curr_dequeue - base_dequeue) / base_dequeue * 100) if base_dequeue > 0 else 0
        status_dequeue = get_performance_status(change_dequeue)
        
        print(f"  {batch_size:^9} | å‡ºé˜Ÿ | {base_dequeue:^10.2f} | {curr_dequeue:^10.2f} | "
              f"{change_dequeue:^6.1f}% | {status_dequeue}")


def compare_formatting_performance(baseline, current):
    """å¯¹æ¯”æ ¼å¼è½¬æ¢æ€§èƒ½"""
    
    print("  è¿­ä»£æ¬¡æ•° | åŸºçº¿ops/s | å½“å‰ops/s | å˜åŒ– | çŠ¶æ€")
    print("  " + "-" * 65)
    
    for base_item, curr_item in zip(baseline, current):
        if base_item['iterations'] != curr_item['iterations']:
            continue
        
        iterations = base_item['iterations']
        base_ops = base_item.get('ops_per_second', 0)
        curr_ops = curr_item.get('ops_per_second', 0)
        
        change = ((curr_ops - base_ops) / base_ops * 100) if base_ops > 0 else 0
        status = get_performance_status(change)
        
        print(f"  {iterations:^10} | {base_ops:^11.2f} | {curr_ops:^11.2f} | "
              f"{change:^6.1f}% | {status}")


def compare_rate_limiter(baseline, current):
    """å¯¹æ¯”é™æµå™¨æ€§èƒ½"""
    
    print("  é…ç½® | åŸºçº¿å‡†ç¡®åº¦ | å½“å‰å‡†ç¡®åº¦ | å˜åŒ– | çŠ¶æ€")
    print("  " + "-" * 65)
    
    for base_item, curr_item in zip(baseline, current):
        config = base_item.get('config', 'æœªçŸ¥')
        base_accuracy = base_item.get('accuracy', 0)
        curr_accuracy = curr_item.get('accuracy', 0)
        
        change = curr_accuracy - base_accuracy
        status = "âœ…" if abs(change) < 1 else "âš ï¸"
        
        print(f"  {config[:20]:^20} | {base_accuracy:^11.2f}% | {curr_accuracy:^11.2f}% | "
              f"{change:^6.2f}% | {status}")


def get_performance_status(change_percent):
    """è·å–æ€§èƒ½å˜åŒ–çŠ¶æ€"""
    if change_percent > 10:
        return "ğŸš€ ä¼˜åŒ–"
    elif change_percent > 0:
        return "âœ… æå‡"
    elif change_percent > -5:
        return "â¡ï¸  æŒå¹³"
    elif change_percent > -10:
        return "âš ï¸  ä¸‹é™"
    else:
        return "âŒ é€€åŒ–"


def generate_summary(baseline, current):
    """ç”Ÿæˆæ€»ç»“"""
    
    improvements = 0
    regressions = 0
    stable = 0
    
    # ç»Ÿè®¡å„é¡¹æŒ‡æ ‡çš„å˜åŒ–
    metrics = []
    
    # å¹¶å‘å¤„ç†
    if "concurrent_processing" in baseline and "concurrent_processing" in current:
        for base, curr in zip(baseline["concurrent_processing"], current["concurrent_processing"]):
            if base['concurrent'] == curr['concurrent']:
                change = ((curr['throughput'] - base['throughput']) / base['throughput'] * 100)
                metrics.append(("å¹¶å‘å¤„ç†", change))
    
    # é˜Ÿåˆ—æ€§èƒ½
    if "queue_performance" in baseline and "queue_performance" in current:
        for base, curr in zip(baseline["queue_performance"], current["queue_performance"]):
            if base['batch_size'] == curr['batch_size']:
                change = ((curr['enqueue_qps'] - base['enqueue_qps']) / base['enqueue_qps'] * 100)
                metrics.append(("é˜Ÿåˆ—å…¥é˜Ÿ", change))
    
    # åˆ†ç±»ç»Ÿè®¡
    for name, change in metrics:
        if change > 5:
            improvements += 1
        elif change < -5:
            regressions += 1
        else:
            stable += 1
    
    total = len(metrics)
    
    print(f"æ€»æµ‹è¯•æŒ‡æ ‡: {total}")
    print(f"  ğŸš€ æ€§èƒ½æå‡: {improvements} ({improvements/total*100:.1f}%)" if total > 0 else "  N/A")
    print(f"  â¡ï¸  æ€§èƒ½æŒå¹³: {stable} ({stable/total*100:.1f}%)" if total > 0 else "  N/A")
    print(f"  âŒ æ€§èƒ½é€€åŒ–: {regressions} ({regressions/total*100:.1f}%)" if total > 0 else "  N/A")
    
    print()
    
    if regressions > 0:
        print("âš ï¸  è­¦å‘Š: å‘ç°æ€§èƒ½é€€åŒ–ï¼Œè¯·æ£€æŸ¥ä»£ç å˜æ›´")
    elif improvements > total * 0.3:
        print("ğŸ‰ æ­å–œ: æ€§èƒ½æœ‰æ˜æ˜¾æå‡ï¼")
    else:
        print("âœ… æ€§èƒ½ä¿æŒç¨³å®š")


def main():
    """ä¸»å‡½æ•°"""
    
    if len(sys.argv) < 3:
        print("ç”¨æ³•: python compare_performance.py <åŸºçº¿æŠ¥å‘Š> <å½“å‰æŠ¥å‘Š>")
        print()
        print("ç¤ºä¾‹:")
        print("  python compare_performance.py \\")
        print("    test_results/demo_stress_test_report.json \\")
        print("    test_results/demo_stress_test_report.json")
        print()
        
        # å°è¯•è‡ªåŠ¨æŸ¥æ‰¾æŠ¥å‘Š
        test_results_dir = Path("test_results")
        if test_results_dir.exists():
            reports = list(test_results_dir.glob("*_report.json"))
            if len(reports) >= 2:
                print("æ‰¾åˆ°çš„æµ‹è¯•æŠ¥å‘Š:")
                for i, report in enumerate(reports[:5]):
                    print(f"  {i+1}. {report}")
                print()
                print("æç¤º: ä½¿ç”¨æœ€æ–°çš„ä¸¤ä¸ªæŠ¥å‘Šè¿›è¡Œå¯¹æ¯”")
            elif len(reports) == 1:
                print(f"æ‰¾åˆ°1ä¸ªæµ‹è¯•æŠ¥å‘Š: {reports[0]}")
                print("æç¤º: éœ€è¦è‡³å°‘2ä¸ªæŠ¥å‘Šæ‰èƒ½è¿›è¡Œå¯¹æ¯”")
        
        return
    
    baseline_path = Path(sys.argv[1])
    current_path = Path(sys.argv[2])
    
    if not baseline_path.exists():
        print(f"âŒ åŸºçº¿æŠ¥å‘Šä¸å­˜åœ¨: {baseline_path}")
        return
    
    if not current_path.exists():
        print(f"âŒ å½“å‰æŠ¥å‘Šä¸å­˜åœ¨: {current_path}")
        return
    
    compare_reports(baseline_path, current_path)
    
    print()


if __name__ == "__main__":
    main()
