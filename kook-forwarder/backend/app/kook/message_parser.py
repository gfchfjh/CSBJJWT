"""
KOOKæ¶ˆæ¯è§£æå™¨ - å®Œæ•´æ”¯æŒæ‰€æœ‰æ¶ˆæ¯ç±»å‹
âœ¨ P0-1ä¼˜åŒ–: æ–°å¢è¡¨æƒ…ååº”ã€å›å¤å¼•ç”¨ã€é“¾æ¥é¢„è§ˆã€é™„ä»¶æ–‡ä»¶æ”¯æŒ
"""
import re
import aiohttp
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from ..utils.logger import logger


@dataclass
class ReactionMessage:
    """è¡¨æƒ…ååº”æ¶ˆæ¯"""
    emoji: str
    users: List[str]
    count: int
    message_id: str


@dataclass
class QuoteMessage:
    """å›å¤å¼•ç”¨æ¶ˆæ¯"""
    quoted_message_id: str
    quoted_content: str
    quoted_author: str
    quoted_author_id: str
    current_content: str
    current_author: str


@dataclass
class LinkPreview:
    """é“¾æ¥é¢„è§ˆ"""
    url: str
    title: Optional[str]
    description: Optional[str]
    image: Optional[str]
    site_name: Optional[str]


@dataclass
class Attachment:
    """æ–‡ä»¶é™„ä»¶"""
    filename: str
    size: int  # bytes
    url: str
    file_type: str
    mime_type: Optional[str]


class FileSizeExceeded(Exception):
    """æ–‡ä»¶å¤§å°è¶…é™å¼‚å¸¸"""
    pass


class KookMessageParser:
    """KOOKæ¶ˆæ¯è§£æå™¨ - å®Œæ•´ç‰ˆ"""
    
    # æœ€å¤§æ–‡ä»¶å¤§å° 50MB
    MAX_FILE_SIZE = 50 * 1024 * 1024
    
    # KOOKè¡¨æƒ…ä»£ç åˆ°emojiçš„æ˜ å°„
    KOOK_EMOJI_MAP = {
        "[å¼€å¿ƒ]": "ğŸ˜Š",
        "[ç¬‘]": "ğŸ˜„",
        "[å¤§ç¬‘]": "ğŸ˜†",
        "[å“ˆå“ˆ]": "ğŸ˜‚",
        "[ç¬‘å“­]": "ğŸ˜‚",
        "[å®³ç¾]": "ğŸ˜³",
        "[çˆ±å¿ƒ]": "â¤ï¸",
        "[å¿ƒç¢]": "ğŸ’”",
        "[èµ]": "ğŸ‘",
        "[è¸©]": "ğŸ‘",
        "[åŠ æ²¹]": "ğŸ’ª",
        "[æ¡æ‰‹]": "ğŸ¤",
        "[é¼“æŒ]": "ğŸ‘",
        "[OK]": "ğŸ‘Œ",
        "[è€¶]": "âœŒï¸",
        "[ç¥ˆç¥·]": "ğŸ™",
        "[å“­]": "ğŸ˜­",
        "[å“­æ³£]": "ğŸ˜¢",
        "[ä¼¤å¿ƒ]": "ğŸ˜",
        "[ç”Ÿæ°”]": "ğŸ˜ ",
        "[æ„¤æ€’]": "ğŸ˜¤",
        "[æƒŠè®¶]": "ğŸ˜²",
        "[éœ‡æƒŠ]": "ğŸ˜±",
        "[ç–‘é—®]": "â“",
        "[æ„Ÿå¹]": "â—",
        "[ç«]": "ğŸ”¥",
        "[é—ªç”µ]": "âš¡",
        "[æ˜Ÿæ˜Ÿ]": "â­",
        "[æœˆäº®]": "ğŸŒ™",
        "[å¤ªé˜³]": "â˜€ï¸",
        "[å½©è™¹]": "ğŸŒˆ",
        "[èŠ±]": "ğŸŒ¸",
    }
    
    def __init__(self):
        self.session: Optional[aiohttp.ClientSession] = None
    
    async def _get_session(self) -> aiohttp.ClientSession:
        """è·å–æˆ–åˆ›å»ºaiohttpä¼šè¯"""
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession()
        return self.session
    
    async def close(self):
        """å…³é—­ä¼šè¯"""
        if self.session and not self.session.closed:
            await self.session.close()
    
    def parse_message_type(self, msg: Dict) -> str:
        """
        åˆ¤æ–­æ¶ˆæ¯ç±»å‹
        
        Returns:
            text / image / file / card / reaction / system
        """
        msg_type = msg.get("type", 1)
        
        # KOOKæ¶ˆæ¯ç±»å‹æ˜ å°„
        # 1: æ–‡æœ¬æ¶ˆæ¯
        # 2: å›¾ç‰‡æ¶ˆæ¯
        # 3: è§†é¢‘æ¶ˆæ¯
        # 4: æ–‡ä»¶æ¶ˆæ¯
        # 8: éŸ³é¢‘æ¶ˆæ¯
        # 9: KMarkdown
        # 10: å¡ç‰‡æ¶ˆæ¯
        
        if msg_type == 1:
            return "text"
        elif msg_type == 2:
            return "image"
        elif msg_type in [3, 4, 8]:
            return "file"
        elif msg_type == 10:
            return "card"
        elif msg_type == 9:
            # KMarkdownå¯èƒ½åŒ…å«æ–‡æœ¬ã€å›¾ç‰‡ã€é“¾æ¥
            content = msg.get("content", "")
            if self._has_image_markdown(content):
                return "image"
            elif self._has_link(content):
                return "link"
            return "text"
        else:
            return "text"
    
    def _has_image_markdown(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡Markdown"""
        return bool(re.search(r'!\[.*?\]\(.*?\)', content))
    
    def _has_link(self, content: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ…å«é“¾æ¥"""
        return bool(re.search(r'https?://\S+', content))
    
    def parse_reactions(self, msg: Dict) -> List[ReactionMessage]:
        """
        è§£æè¡¨æƒ…ååº”
        
        KOOKè¡¨æƒ…ååº”æ ¼å¼:
        {
            "reactions": [
                {
                    "emoji": {"id": "xxx", "name": "å¼€å¿ƒ"},
                    "count": 2,
                    "me": false,
                    "users": ["user1", "user2"]
                }
            ]
        }
        
        Returns:
            ReactionMessageåˆ—è¡¨
        """
        reactions = msg.get("reactions", [])
        result = []
        
        for reaction in reactions:
            emoji_data = reaction.get("emoji", {})
            emoji_name = emoji_data.get("name", "")
            
            # è½¬æ¢KOOKè¡¨æƒ…ä»£ç ä¸ºemoji
            emoji = self.KOOK_EMOJI_MAP.get(f"[{emoji_name}]", emoji_name)
            
            users = reaction.get("users", [])
            count = reaction.get("count", 0)
            message_id = msg.get("msg_id", "")
            
            result.append(ReactionMessage(
                emoji=emoji,
                users=users,
                count=count,
                message_id=message_id
            ))
        
        return result
    
    def parse_quote(self, msg: Dict) -> Optional[QuoteMessage]:
        """
        è§£æå›å¤å¼•ç”¨
        
        KOOKå›å¤æ ¼å¼:
        {
            "quote": {
                "id": "quoted_msg_id",
                "type": 1,
                "content": "è¢«å¼•ç”¨çš„æ¶ˆæ¯å†…å®¹",
                "create_at": 1234567890,
                "author": {
                    "id": "user_id",
                    "username": "ç”¨æˆ·å",
                    "avatar": "avatar_url"
                }
            },
            "content": "å½“å‰å›å¤å†…å®¹"
        }
        
        Returns:
            QuoteMessageå¯¹è±¡æˆ–None
        """
        quote_data = msg.get("quote")
        if not quote_data:
            return None
        
        try:
            quoted_author = quote_data.get("author", {})
            current_author_data = msg.get("author", {})
            
            return QuoteMessage(
                quoted_message_id=quote_data.get("id", ""),
                quoted_content=quote_data.get("content", ""),
                quoted_author=quoted_author.get("username", "æœªçŸ¥ç”¨æˆ·"),
                quoted_author_id=quoted_author.get("id", ""),
                current_content=msg.get("content", ""),
                current_author=current_author_data.get("username", "æœªçŸ¥ç”¨æˆ·")
            )
        except Exception as e:
            logger.error(f"è§£æå¼•ç”¨æ¶ˆæ¯å¤±è´¥: {e}")
            return None
    
    async def parse_link_preview(self, url: str) -> Optional[LinkPreview]:
        """
        è§£æé“¾æ¥é¢„è§ˆï¼ˆè·å–Open Graphå…ƒæ•°æ®ï¼‰
        
        Args:
            url: è¦è§£æçš„URL
        
        Returns:
            LinkPreviewå¯¹è±¡æˆ–None
        """
        try:
            session = await self._get_session()
            
            async with session.get(url, timeout=aiohttp.ClientTimeout(total=5)) as response:
                if response.status != 200:
                    return None
                
                html = await response.text()
                
                # è§£æOpen Graphæ ‡ç­¾
                title = self._extract_og_tag(html, "og:title") or self._extract_title_tag(html)
                description = self._extract_og_tag(html, "og:description")
                image = self._extract_og_tag(html, "og:image")
                site_name = self._extract_og_tag(html, "og:site_name")
                
                if not title:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡é¢˜ï¼Œä½¿ç”¨URL
                    title = url
                
                return LinkPreview(
                    url=url,
                    title=title,
                    description=description,
                    image=image,
                    site_name=site_name
                )
                
        except asyncio.TimeoutError:
            logger.warning(f"é“¾æ¥é¢„è§ˆè¶…æ—¶: {url}")
            return None
        except Exception as e:
            logger.error(f"è§£æé“¾æ¥é¢„è§ˆå¤±è´¥ {url}: {e}")
            return None
    
    def _extract_og_tag(self, html: str, property_name: str) -> Optional[str]:
        """æå–Open Graphæ ‡ç­¾"""
        pattern = f'<meta\\s+property=["\']?{property_name}["\']?\\s+content=["\']([^"\']+)["\']'
        match = re.search(pattern, html, re.IGNORECASE)
        if match:
            return match.group(1)
        
        # å°è¯•åå‘åŒ¹é…ï¼ˆcontentåœ¨å‰ï¼‰
        pattern = f'<meta\\s+content=["\']([^"\']+)["\']\\s+property=["\']?{property_name}["\']?'
        match = re.search(pattern, html, re.IGNORECASE)
        if match:
            return match.group(1)
        
        return None
    
    def _extract_title_tag(self, html: str) -> Optional[str]:
        """æå–<title>æ ‡ç­¾"""
        match = re.search(r'<title>([^<]+)</title>', html, re.IGNORECASE)
        return match.group(1) if match else None
    
    def parse_attachment(self, msg: Dict) -> Optional[Attachment]:
        """
        è§£ææ–‡ä»¶é™„ä»¶
        
        KOOKé™„ä»¶æ ¼å¼:
        {
            "type": 4,  # æ–‡ä»¶æ¶ˆæ¯
            "attachments": {
                "type": "file",
                "url": "https://...",
                "name": "æ–‡ä»¶å.pdf",
                "file_type": "application/pdf",
                "size": 1024000  # bytes
            }
        }
        
        Returns:
            Attachmentå¯¹è±¡æˆ–None
        
        Raises:
            FileSizeExceeded: æ–‡ä»¶è¶…è¿‡50MB
        """
        attachment_data = msg.get("attachments")
        if not attachment_data:
            # å°è¯•ä»contentä¸­æå–ï¼ˆæŸäº›æƒ…å†µä¸‹é™„ä»¶ä¿¡æ¯åœ¨contentä¸­ï¼‰
            content = msg.get("content", "")
            if content.startswith("http"):
                # ç®€å•çš„æ–‡ä»¶URL
                return Attachment(
                    filename=content.split("/")[-1],
                    size=0,  # æœªçŸ¥å¤§å°
                    url=content,
                    file_type="unknown",
                    mime_type=None
                )
            return None
        
        try:
            filename = attachment_data.get("name", "unknown")
            size = attachment_data.get("size", 0)
            url = attachment_data.get("url", "")
            file_type = attachment_data.get("file_type", "unknown")
            mime_type = attachment_data.get("type")
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°é™åˆ¶
            if size > self.MAX_FILE_SIZE:
                raise FileSizeExceeded(
                    f"æ–‡ä»¶ {filename} å¤§å° {size/1024/1024:.2f}MB è¶…è¿‡50MBé™åˆ¶"
                )
            
            return Attachment(
                filename=filename,
                size=size,
                url=url,
                file_type=file_type,
                mime_type=mime_type
            )
            
        except FileSizeExceeded:
            raise
        except Exception as e:
            logger.error(f"è§£æé™„ä»¶å¤±è´¥: {e}")
            return None
    
    def parse_mentions(self, msg: Dict) -> List[Dict]:
        """
        è§£æ@æåŠ
        
        KOOK @æåŠæ ¼å¼:
        {
            "mention": ["user_id_1", "user_id_2"],
            "mention_all": false,
            "mention_roles": ["role_id_1"],
            "mention_here": false
        }
        
        Returns:
            [
                {"type": "user", "user_id": "xxx", "username": "xxx"},
                {"type": "role", "role_id": "xxx", "role_name": "xxx"},
                {"type": "all"},
                {"type": "here"}
            ]
        """
        mentions = []
        
        # @ç”¨æˆ·
        mention_users = msg.get("mention", [])
        for user_id in mention_users:
            # å°è¯•ä»æ¶ˆæ¯å†…å®¹ä¸­æå–ç”¨æˆ·å
            username = self._extract_username_from_mention(msg.get("content", ""), user_id)
            mentions.append({
                "type": "user",
                "user_id": user_id,
                "username": username or f"ç”¨æˆ·{user_id[:6]}"
            })
        
        # @è§’è‰²
        mention_roles = msg.get("mention_roles", [])
        for role_id in mention_roles:
            mentions.append({
                "type": "role",
                "role_id": role_id,
                "role_name": f"è§’è‰²{role_id[:6]}"
            })
        
        # @å…¨ä½“æˆå‘˜
        if msg.get("mention_all", False):
            mentions.append({"type": "all"})
        
        # @åœ¨çº¿æˆå‘˜
        if msg.get("mention_here", False):
            mentions.append({"type": "here"})
        
        return mentions
    
    def _extract_username_from_mention(self, content: str, user_id: str) -> Optional[str]:
        """ä»æ¶ˆæ¯å†…å®¹ä¸­æå–@ç”¨æˆ·å"""
        # KOOK @æ ¼å¼: @ç”¨æˆ·å æˆ– (met)user_id(met)
        pattern = f'\\(met\\){user_id}\\(met\\)@([^\\s]+)'
        match = re.search(pattern, content)
        return match.group(1) if match else None
    
    def parse_images(self, msg: Dict) -> List[str]:
        """
        è§£æå›¾ç‰‡URLåˆ—è¡¨
        
        æ”¯æŒå¤šç§æ ¼å¼:
        1. type=2 å›¾ç‰‡æ¶ˆæ¯
        2. KMarkdownä¸­çš„å›¾ç‰‡
        3. attachmentsä¸­çš„å›¾ç‰‡
        
        Returns:
            å›¾ç‰‡URLåˆ—è¡¨
        """
        images = []
        
        # æ–¹å¼1: å›¾ç‰‡æ¶ˆæ¯ç±»å‹
        if msg.get("type") == 2:
            content = msg.get("content", "")
            if content.startswith("http"):
                images.append(content)
        
        # æ–¹å¼2: KMarkdownå›¾ç‰‡è¯­æ³• ![alt](url)
        content = msg.get("content", "")
        markdown_images = re.findall(r'!\[.*?\]\((https?://[^\)]+)\)', content)
        images.extend(markdown_images)
        
        # æ–¹å¼3: attachments
        attachments = msg.get("attachments", {})
        if attachments and attachments.get("type") == "image":
            url = attachments.get("url")
            if url:
                images.append(url)
        
        return list(set(images))  # å»é‡
    
    async def parse_complete_message(self, msg: Dict) -> Dict[str, Any]:
        """
        å®Œæ•´è§£ææ¶ˆæ¯ï¼ˆä¸€æ¬¡æ€§è§£ææ‰€æœ‰å†…å®¹ï¼‰
        
        Returns:
            {
                "message_id": "...",
                "type": "text/image/file/...",
                "content": "åŸå§‹å†…å®¹",
                "author": {...},
                "reactions": [ReactionMessage, ...],
                "quote": QuoteMessage or None,
                "link_preview": LinkPreview or None,
                "attachment": Attachment or None,
                "images": ["url1", "url2"],
                "mentions": [{...}, ...],
                "timestamp": 1234567890,
                "channel_id": "...",
                "guild_id": "..."
            }
        """
        result = {
            "message_id": msg.get("msg_id", ""),
            "type": self.parse_message_type(msg),
            "content": msg.get("content", ""),
            "author": msg.get("author", {}),
            "timestamp": msg.get("msg_timestamp", 0),
            "channel_id": msg.get("target_id", ""),
            "guild_id": msg.get("guild_id", ""),
        }
        
        # è§£æè¡¨æƒ…ååº”
        result["reactions"] = self.parse_reactions(msg)
        
        # è§£æå›å¤å¼•ç”¨
        result["quote"] = self.parse_quote(msg)
        
        # è§£æå›¾ç‰‡
        result["images"] = self.parse_images(msg)
        
        # è§£æ@æåŠ
        result["mentions"] = self.parse_mentions(msg)
        
        # è§£æé™„ä»¶
        try:
            result["attachment"] = self.parse_attachment(msg)
        except FileSizeExceeded as e:
            logger.warning(str(e))
            result["attachment"] = None
            result["attachment_error"] = str(e)
        
        # è§£æé“¾æ¥é¢„è§ˆï¼ˆå¼‚æ­¥ï¼Œå¯èƒ½è¾ƒæ…¢ï¼‰
        links = re.findall(r'https?://\S+', result["content"])
        if links:
            # åªè§£æç¬¬ä¸€ä¸ªé“¾æ¥
            result["link_preview"] = await self.parse_link_preview(links[0])
        else:
            result["link_preview"] = None
        
        return result


# å…¨å±€å®ä¾‹
message_parser = KookMessageParser()
