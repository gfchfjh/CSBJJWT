"""
KOOKæ¶ˆæ¯è½¬å‘ç³»ç»Ÿ - å…¨é¢å‹åŠ›æµ‹è¯•
æ ¹æ®éœ€æ±‚æ–‡æ¡£å¯¹æ‰€æœ‰åŠŸèƒ½è¿›è¡Œå‹åŠ›æµ‹è¯•
"""
import asyncio
import aiohttp
import time
import random
import json
import sys
import os
import sqlite3
import psutil
import traceback
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import statistics

# æ·»åŠ åç«¯è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "backend"))

# æµ‹è¯•é…ç½®
TEST_CONFIG = {
    "api_base_url": "http://127.0.0.1:9527",
    "redis_host": "127.0.0.1",
    "redis_port": 6379,
    
    # å‹åŠ›æµ‹è¯•å‚æ•°
    "concurrent_users": [1, 5, 10, 20, 50, 100],  # å¹¶å‘ç”¨æˆ·æ•°
    "test_duration": 30,  # æ¯ä¸ªæµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    "message_batch_sizes": [10, 50, 100, 500, 1000, 5000],  # æ¶ˆæ¯æ‰¹é‡å¤§å°
    "large_message_sizes": [1000, 5000, 10000, 50000],  # å¤§æ¶ˆæ¯å¤§å°ï¼ˆå­—ç¬¦ï¼‰
    "image_sizes": [(800, 600), (1920, 1080), (4096, 3072), (8192, 6144)],  # å›¾ç‰‡å°ºå¯¸
    
    # é™æµé…ç½®
    "discord_rate": (5, 5),  # 5è¯·æ±‚/5ç§’
    "telegram_rate": (30, 1),  # 30è¯·æ±‚/1ç§’
    "feishu_rate": (20, 1),  # 20è¯·æ±‚/1ç§’
}

# æµ‹è¯•ç»“æœå­˜å‚¨
test_results = {
    "start_time": None,
    "end_time": None,
    "system_info": {},
    "tests": {},
    "summary": {}
}


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.initial_memory = self.process.memory_info().rss
        self.initial_cpu = self.process.cpu_percent()
        self.samples = []
    
    def record_sample(self):
        """è®°å½•æ€§èƒ½æ ·æœ¬"""
        sample = {
            "timestamp": time.time(),
            "memory_mb": self.process.memory_info().rss / 1024 / 1024,
            "cpu_percent": self.process.cpu_percent(),
            "threads": self.process.num_threads(),
            "connections": len(self.process.connections()) if hasattr(self.process, 'connections') else 0
        }
        self.samples.append(sample)
        return sample
    
    def get_stats(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.samples:
            return {}
        
        memory_values = [s["memory_mb"] for s in self.samples]
        cpu_values = [s["cpu_percent"] for s in self.samples]
        
        return {
            "memory": {
                "min_mb": min(memory_values),
                "max_mb": max(memory_values),
                "avg_mb": statistics.mean(memory_values),
                "growth_mb": memory_values[-1] - memory_values[0]
            },
            "cpu": {
                "min_percent": min(cpu_values),
                "max_percent": max(cpu_values),
                "avg_percent": statistics.mean(cpu_values)
            },
            "threads": {
                "min": min(s["threads"] for s in self.samples),
                "max": max(s["threads"] for s in self.samples)
            }
        }


class ComprehensiveStressTest:
    """å…¨é¢å‹åŠ›æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.api_base = config["api_base_url"]
        self.session: Optional[aiohttp.ClientSession] = None
        self.monitor = PerformanceMonitor()
        
        # ç»Ÿè®¡è®¡æ•°å™¨
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.response_times = []
        self.errors = []
    
    async def setup(self):
        """åˆå§‹åŒ–æµ‹è¯•ç¯å¢ƒ"""
        print("=" * 100)
        print("KOOKæ¶ˆæ¯è½¬å‘ç³»ç»Ÿ - å…¨é¢å‹åŠ›æµ‹è¯•")
        print("=" * 100)
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"APIåœ°å€: {self.api_base}")
        
        # è®°å½•ç³»ç»Ÿä¿¡æ¯
        test_results["system_info"] = {
            "platform": sys.platform,
            "python_version": sys.version,
            "cpu_count": psutil.cpu_count(),
            "total_memory_gb": psutil.virtual_memory().total / 1024 / 1024 / 1024,
            "available_memory_gb": psutil.virtual_memory().available / 1024 / 1024 / 1024
        }
        
        print(f"ç³»ç»Ÿ: {test_results['system_info']['platform']}")
        print(f"CPUæ ¸å¿ƒ: {test_results['system_info']['cpu_count']}")
        print(f"å†…å­˜: {test_results['system_info']['total_memory_gb']:.2f}GB")
        print("=" * 100)
        print()
        
        # åˆ›å»ºHTTPä¼šè¯
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)
        
        # æ£€æŸ¥æœåŠ¡æ˜¯å¦è¿è¡Œ
        try:
            async with self.session.get(f"{self.api_base}/health") as resp:
                if resp.status == 200:
                    print("âœ… åç«¯æœåŠ¡è¿è¡Œæ­£å¸¸\n")
                    return True
                else:
                    print(f"âŒ åç«¯æœåŠ¡å“åº”å¼‚å¸¸ (status={resp.status})\n")
                    return False
        except Exception as e:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°åç«¯æœåŠ¡: {e}")
            print("è¯·å…ˆå¯åŠ¨åç«¯æœåŠ¡: cd backend && python -m app.main\n")
            return False
    
    async def teardown(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        if self.session:
            await self.session.close()
    
    async def make_request(self, method: str, endpoint: str, **kwargs) -> Dict[str, Any]:
        """å‘é€HTTPè¯·æ±‚å¹¶è®°å½•æ€§èƒ½"""
        self.total_requests += 1
        start_time = time.time()
        
        try:
            url = f"{self.api_base}{endpoint}"
            async with self.session.request(method, url, **kwargs) as resp:
                response_time = time.time() - start_time
                self.response_times.append(response_time)
                
                if resp.status < 400:
                    self.successful_requests += 1
                    status = "success"
                else:
                    self.failed_requests += 1
                    status = "failed"
                
                try:
                    data = await resp.json() if resp.content_type == 'application/json' else None
                except:
                    data = None
                
                return {
                    "status": resp.status,
                    "response_time": response_time,
                    "data": data,
                    "result": status
                }
        except Exception as e:
            response_time = time.time() - start_time
            self.failed_requests += 1
            error_msg = f"{type(e).__name__}: {str(e)}"
            self.errors.append(error_msg)
            
            return {
                "status": 0,
                "response_time": response_time,
                "error": error_msg,
                "result": "error"
            }
    
    # ==================== æµ‹è¯•1: APIç«¯ç‚¹å…¨è¦†ç›–æµ‹è¯• ====================
    
    async def test_all_api_endpoints(self) -> Dict[str, Any]:
        """æµ‹è¯•1: æµ‹è¯•æ‰€æœ‰APIç«¯ç‚¹"""
        print("\n" + "=" * 100)
        print("æµ‹è¯•1: APIç«¯ç‚¹å…¨è¦†ç›–æµ‹è¯•")
        print("=" * 100)
        
        endpoints = [
            # åŸºç¡€ç«¯ç‚¹
            ("GET", "/", "æ ¹è·¯å¾„"),
            ("GET", "/health", "å¥åº·æ£€æŸ¥"),
            
            # è´¦å·ç®¡ç†
            ("GET", "/api/accounts", "è´¦å·åˆ—è¡¨"),
            ("GET", "/api/accounts/status", "è´¦å·çŠ¶æ€"),
            
            # Boté…ç½®
            ("GET", "/api/bots", "Botåˆ—è¡¨"),
            ("GET", "/api/bots/platforms", "å¹³å°åˆ—è¡¨"),
            
            # é¢‘é“æ˜ å°„
            ("GET", "/api/mappings", "æ˜ å°„åˆ—è¡¨"),
            ("GET", "/api/mappings/stats", "æ˜ å°„ç»Ÿè®¡"),
            
            # æ—¥å¿—æŸ¥è¯¢
            ("GET", "/api/logs?limit=10", "æ—¥å¿—æŸ¥è¯¢"),
            ("GET", "/api/logs/stats", "æ—¥å¿—ç»Ÿè®¡"),
            ("GET", "/api/logs/failed", "å¤±è´¥æ—¥å¿—"),
            
            # ç³»ç»ŸçŠ¶æ€
            ("GET", "/api/system/status", "ç³»ç»ŸçŠ¶æ€"),
            ("GET", "/api/system/stats", "ç³»ç»Ÿç»Ÿè®¡"),
            ("GET", "/api/system/config", "ç³»ç»Ÿé…ç½®"),
            
            # å¥åº·æ£€æŸ¥
            ("GET", "/api/health", "è¯¦ç»†å¥åº·æ£€æŸ¥"),
            
            # æ›´æ–°æ£€æŸ¥
            ("GET", "/api/updates/check", "æ£€æŸ¥æ›´æ–°"),
        ]
        
        results = []
        start_time = time.time()
        
        for method, endpoint, name in endpoints:
            print(f"æµ‹è¯• {name:30s} ({method:4s} {endpoint:40s})...", end=" ")
            result = await self.make_request(method, endpoint)
            
            if result["result"] == "success":
                print(f"âœ… {result['response_time']*1000:6.2f}ms")
            else:
                print(f"âŒ å¤±è´¥ (status={result['status']})")
            
            results.append({
                "name": name,
                "method": method,
                "endpoint": endpoint,
                "status": result["result"],
                "response_time": result["response_time"],
                "http_status": result["status"]
            })
        
        elapsed_time = time.time() - start_time
        successful = sum(1 for r in results if r["status"] == "success")
        
        print(f"\næ€»è®¡: {len(endpoints)}ä¸ªç«¯ç‚¹, æˆåŠŸ: {successful}, å¤±è´¥: {len(endpoints)-successful}, è€—æ—¶: {elapsed_time:.2f}s")
        
        return {
            "test_name": "APIç«¯ç‚¹å…¨è¦†ç›–æµ‹è¯•",
            "total_endpoints": len(endpoints),
            "successful": successful,
            "failed": len(endpoints) - successful,
            "elapsed_time": elapsed_time,
            "results": results
        }
    
    # ==================== æµ‹è¯•2: å¹¶å‘è¯·æ±‚å‹åŠ›æµ‹è¯• ====================
    
    async def test_concurrent_load(self, concurrent: int) -> Dict[str, Any]:
        """æµ‹è¯•2: å¹¶å‘è¯·æ±‚å‹åŠ›æµ‹è¯•"""
        print(f"\næµ‹è¯•å¹¶å‘åº¦: {concurrent:4d}...", end=" ")
        
        # è®°å½•æ€§èƒ½å‰
        self.monitor.record_sample()
        
        start_time = time.time()
        tasks = []
        
        # åˆ›å»ºå¹¶å‘ä»»åŠ¡
        endpoints = [
            ("GET", "/api/system/status"),
            ("GET", "/api/accounts"),
            ("GET", "/api/bots"),
            ("GET", "/api/mappings"),
            ("GET", f"/api/logs?limit=10"),
        ]
        
        for i in range(concurrent):
            method, endpoint = random.choice(endpoints)
            tasks.append(self.make_request(method, endpoint))
        
        # æ‰§è¡Œå¹¶å‘è¯·æ±‚
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        elapsed_time = time.time() - start_time
        
        # ç»Ÿè®¡ç»“æœ
        successful = sum(1 for r in results if isinstance(r, dict) and r.get("result") == "success")
        failed = concurrent - successful
        
        response_times = [r["response_time"] for r in results if isinstance(r, dict) and "response_time" in r]
        
        if response_times:
            avg_response_time = statistics.mean(response_times)
            max_response_time = max(response_times)
            min_response_time = min(response_times)
            p50 = statistics.median(response_times)
            p90 = statistics.quantiles(response_times, n=10)[8] if len(response_times) > 10 else max_response_time
            p99 = statistics.quantiles(response_times, n=100)[98] if len(response_times) > 100 else max_response_time
        else:
            avg_response_time = max_response_time = min_response_time = p50 = p90 = p99 = 0
        
        qps = concurrent / elapsed_time if elapsed_time > 0 else 0
        
        # è®°å½•æ€§èƒ½å
        perf_sample = self.monitor.record_sample()
        
        print(f"âœ… QPS: {qps:7.2f}, å¹³å‡: {avg_response_time*1000:6.2f}ms, P99: {p99*1000:6.2f}ms, å†…å­˜: {perf_sample['memory_mb']:.1f}MB")
        
        return {
            "concurrent": concurrent,
            "total_requests": concurrent,
            "successful": successful,
            "failed": failed,
            "elapsed_time": elapsed_time,
            "qps": qps,
            "response_time": {
                "avg": avg_response_time,
                "max": max_response_time,
                "min": min_response_time,
                "p50": p50,
                "p90": p90,
                "p99": p99
            },
            "memory_mb": perf_sample['memory_mb'],
            "cpu_percent": perf_sample['cpu_percent']
        }
    
    # ==================== æµ‹è¯•3: æ•°æ®åº“é«˜è´Ÿè½½æµ‹è¯• ====================
    
    async def test_database_stress(self) -> Dict[str, Any]:
        """æµ‹è¯•3: æ•°æ®åº“é«˜è´Ÿè½½æµ‹è¯•"""
        print("\n" + "=" * 100)
        print("æµ‹è¯•3: æ•°æ®åº“é«˜è´Ÿè½½æµ‹è¯•")
        print("=" * 100)
        
        db_path = Path(__file__).parent / "backend" / "data" / "kook_forwarder.db"
        
        if not db_path.exists():
            print("âš ï¸  æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºæµ‹è¯•æ•°æ®åº“...")
            db_path.parent.mkdir(parents=True, exist_ok=True)
            conn = sqlite3.connect(db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºæµ‹è¯•è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS message_logs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    kook_message_id TEXT NOT NULL UNIQUE,
                    kook_channel_id TEXT NOT NULL,
                    content TEXT,
                    message_type TEXT,
                    sender_name TEXT,
                    target_platform TEXT,
                    target_channel TEXT,
                    status TEXT,
                    latency_ms INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS channel_mappings (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    kook_channel_id TEXT NOT NULL,
                    kook_channel_name TEXT NOT NULL,
                    target_platform TEXT NOT NULL,
                    target_channel TEXT NOT NULL
                )
            """)
            
            conn.commit()
            conn.close()
            print("âœ… æµ‹è¯•æ•°æ®åº“å·²åˆ›å»º")
        
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()
        results = {}
        
        # æµ‹è¯•1: ç®€å•æŸ¥è¯¢æ€§èƒ½ï¼ˆé«˜é¢‘ï¼‰
        print("\næµ‹è¯•ç®€å•æŸ¥è¯¢ï¼ˆ10000æ¬¡ï¼‰...", end=" ")
        start = time.time()
        for _ in range(10000):
            cursor.execute("SELECT COUNT(*) FROM message_logs")
            cursor.fetchone()
        simple_query_time = time.time() - start
        qps = 10000 / simple_query_time
        print(f"âœ… è€—æ—¶: {simple_query_time:.3f}s, QPS: {qps:.0f}")
        results["simple_query"] = {"time": simple_query_time, "qps": qps, "iterations": 10000}
        
        # æµ‹è¯•2: å¤æ‚æŸ¥è¯¢æ€§èƒ½ï¼ˆJOIN + ORDER BYï¼‰
        print("æµ‹è¯•å¤æ‚æŸ¥è¯¢ï¼ˆ1000æ¬¡ï¼‰...", end=" ")
        start = time.time()
        for _ in range(1000):
            cursor.execute("""
                SELECT ml.*, cm.kook_channel_name 
                FROM message_logs ml
                LEFT JOIN channel_mappings cm ON ml.kook_channel_id = cm.kook_channel_id
                WHERE ml.status = 'success'
                ORDER BY ml.created_at DESC
                LIMIT 10
            """)
            cursor.fetchall()
        complex_query_time = time.time() - start
        qps = 1000 / complex_query_time
        print(f"âœ… è€—æ—¶: {complex_query_time:.3f}s, QPS: {qps:.0f}")
        results["complex_query"] = {"time": complex_query_time, "qps": qps, "iterations": 1000}
        
        # æµ‹è¯•3: æ‰¹é‡æ’å…¥æ€§èƒ½
        print("æµ‹è¯•æ‰¹é‡æ’å…¥ï¼ˆ10000æ¡ï¼‰...", end=" ")
        start = time.time()
        cursor.execute("BEGIN TRANSACTION")
        for i in range(10000):
            cursor.execute("""
                INSERT OR IGNORE INTO message_logs 
                (kook_message_id, kook_channel_id, content, message_type, sender_name, 
                 target_platform, target_channel, status, latency_ms)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                f"stress_test_{int(time.time()*1000000)}_{i}",
                "test_channel",
                f"å‹åŠ›æµ‹è¯•æ¶ˆæ¯ {i}",
                "text",
                "å‹åŠ›æµ‹è¯•",
                "discord",
                "test_target",
                "success",
                random.randint(50, 500)
            ))
        cursor.execute("COMMIT")
        insert_time = time.time() - start
        qps = 10000 / insert_time
        print(f"âœ… è€—æ—¶: {insert_time:.3f}s, QPS: {qps:.0f}")
        results["batch_insert"] = {"time": insert_time, "qps": qps, "count": 10000}
        
        # æµ‹è¯•4: å¹¶å‘æ›´æ–°æ€§èƒ½
        print("æµ‹è¯•æ‰¹é‡æ›´æ–°ï¼ˆ5000æ¡ï¼‰...", end=" ")
        start = time.time()
        cursor.execute("BEGIN TRANSACTION")
        cursor.execute("""
            UPDATE message_logs 
            SET status = 'retried', latency_ms = latency_ms + 100
            WHERE kook_channel_id = 'test_channel'
            LIMIT 5000
        """)
        cursor.execute("COMMIT")
        update_time = time.time() - start
        qps = 5000 / update_time if update_time > 0 else 0
        print(f"âœ… è€—æ—¶: {update_time:.3f}s, QPS: {qps:.0f}")
        results["batch_update"] = {"time": update_time, "qps": qps, "count": 5000}
        
        # æµ‹è¯•5: æ‰¹é‡åˆ é™¤æ€§èƒ½
        print("æµ‹è¯•æ‰¹é‡åˆ é™¤ï¼ˆæ¸…ç†æµ‹è¯•æ•°æ®ï¼‰...", end=" ")
        start = time.time()
        cursor.execute("DELETE FROM message_logs WHERE kook_channel_id = 'test_channel'")
        conn.commit()
        delete_time = time.time() - start
        deleted_rows = cursor.rowcount
        print(f"âœ… è€—æ—¶: {delete_time:.3f}s, åˆ é™¤: {deleted_rows}æ¡")
        results["batch_delete"] = {"time": delete_time, "count": deleted_rows}
        
        # æµ‹è¯•6: æ•°æ®åº“å¤§å°
        cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
        db_size = cursor.fetchone()[0]
        print(f"\næ•°æ®åº“å¤§å°: {db_size / 1024 / 1024:.2f}MB")
        results["database_size_mb"] = db_size / 1024 / 1024
        
        conn.close()
        
        return {
            "test_name": "æ•°æ®åº“é«˜è´Ÿè½½æµ‹è¯•",
            "status": "success",
            "results": results
        }
    
    # ==================== æµ‹è¯•4: æ¶ˆæ¯é˜Ÿåˆ—æé™æµ‹è¯• ====================
    
    async def test_message_queue_extreme(self) -> Dict[str, Any]:
        """æµ‹è¯•4: æ¶ˆæ¯é˜Ÿåˆ—æé™æµ‹è¯•"""
        print("\n" + "=" * 100)
        print("æµ‹è¯•4: æ¶ˆæ¯é˜Ÿåˆ—æé™æµ‹è¯•")
        print("=" * 100)
        
        try:
            import redis
            r = redis.Redis(
                host=self.config["redis_host"],
                port=self.config["redis_port"],
                decode_responses=True
            )
            
            # æµ‹è¯•è¿æ¥
            r.ping()
            print("âœ… Redisè¿æ¥æˆåŠŸ\n")
            
            queue_results = []
            
            for batch_size in self.config["message_batch_sizes"]:
                print(f"æµ‹è¯•æ‰¹é‡å¤§å°: {batch_size:5d}...", end=" ")
                
                # æµ‹è¯•å…¥é˜Ÿæ€§èƒ½
                messages = []
                for i in range(batch_size):
                    message = {
                        "id": f"stress_{int(time.time()*1000000)}_{i}",
                        "type": "text",
                        "content": f"å‹åŠ›æµ‹è¯•æ¶ˆæ¯ {i}",
                        "timestamp": time.time()
                    }
                    messages.append(json.dumps(message))
                
                start = time.time()
                pipe = r.pipeline()
                for msg in messages:
                    pipe.lpush("stress_test_queue", msg)
                pipe.execute()
                enqueue_time = time.time() - start
                enqueue_qps = batch_size / enqueue_time
                
                # æµ‹è¯•å‡ºé˜Ÿæ€§èƒ½
                start = time.time()
                pipe = r.pipeline()
                for _ in range(batch_size):
                    pipe.rpop("stress_test_queue")
                pipe.execute()
                dequeue_time = time.time() - start
                dequeue_qps = batch_size / dequeue_time
                
                print(f"âœ… å…¥é˜Ÿ: {enqueue_time:.3f}s ({enqueue_qps:.0f} msg/s), å‡ºé˜Ÿ: {dequeue_time:.3f}s ({dequeue_qps:.0f} msg/s)")
                
                queue_results.append({
                    "batch_size": batch_size,
                    "enqueue_time": enqueue_time,
                    "enqueue_qps": enqueue_qps,
                    "dequeue_time": dequeue_time,
                    "dequeue_qps": dequeue_qps,
                    "total_time": enqueue_time + dequeue_time
                })
            
            # æµ‹è¯•é˜Ÿåˆ—å¤§å°é™åˆ¶
            print("\næµ‹è¯•é˜Ÿåˆ—å®¹é‡...", end=" ")
            queue_name = "stress_capacity_test"
            r.delete(queue_name)
            
            start = time.time()
            for i in range(100000):  # æ’å…¥10ä¸‡æ¡æ¶ˆæ¯
                r.lpush(queue_name, f"msg_{i}")
            capacity_time = time.time() - start
            queue_length = r.llen(queue_name)
            r.delete(queue_name)
            
            print(f"âœ… æ’å…¥10ä¸‡æ¡æ¶ˆæ¯è€—æ—¶: {capacity_time:.3f}s, QPS: {100000/capacity_time:.0f}")
            
            return {
                "test_name": "æ¶ˆæ¯é˜Ÿåˆ—æé™æµ‹è¯•",
                "status": "success",
                "batch_results": queue_results,
                "capacity_test": {
                    "messages": 100000,
                    "time": capacity_time,
                    "qps": 100000 / capacity_time
                }
            }
            
        except Exception as e:
            print(f"âŒ Redisæµ‹è¯•å¤±è´¥: {e}")
            traceback.print_exc()
            return {"status": "failed", "error": str(e)}
    
    # ==================== æµ‹è¯•5: é™æµå™¨å‹åŠ›æµ‹è¯• ====================
    
    async def test_rate_limiter_stress(self) -> Dict[str, Any]:
        """æµ‹è¯•5: é™æµå™¨å‹åŠ›æµ‹è¯•"""
        print("\n" + "=" * 100)
        print("æµ‹è¯•5: é™æµå™¨å‹åŠ›æµ‹è¯•")
        print("=" * 100)
        
        try:
            sys.path.insert(0, str(Path(__file__).parent / "backend"))
            from app.utils.rate_limiter import RateLimiter
            
            results = []
            
            # æµ‹è¯•ä¸åŒå¹³å°çš„é™æµé…ç½®
            configs = [
                (5, 5, "Discord", "Discordé™æµï¼ˆ5è¯·æ±‚/5ç§’ï¼‰"),
                (30, 1, "Telegram", "Telegramé™æµï¼ˆ30è¯·æ±‚/1ç§’ï¼‰"),
                (20, 1, "Feishu", "é£ä¹¦é™æµï¼ˆ20è¯·æ±‚/1ç§’ï¼‰"),
                (100, 1, "é«˜è´Ÿè½½", "é«˜è´Ÿè½½é™æµï¼ˆ100è¯·æ±‚/1ç§’ï¼‰"),
            ]
            
            for calls, period, platform, name in configs:
                print(f"\næµ‹è¯• {name}...")
                limiter = RateLimiter(calls=calls, period=period)
                
                start = time.time()
                acquire_times = []
                
                # å‘é€calls*3ä¸ªè¯·æ±‚ï¼Œæµ‹è¯•é™æµæ•ˆæœ
                test_requests = calls * 3
                for i in range(test_requests):
                    acquire_start = time.time()
                    await limiter.acquire()
                    acquire_time = time.time() - acquire_start
                    acquire_times.append(acquire_time)
                
                total_time = time.time() - start
                actual_qps = test_requests / total_time
                expected_qps = calls / period
                
                print(f"  å‘é€è¯·æ±‚: {test_requests}")
                print(f"  æ€»è€—æ—¶: {total_time:.3f}s")
                print(f"  å®é™…QPS: {actual_qps:.2f}")
                print(f"  æœŸæœ›QPS: {expected_qps:.2f}")
                print(f"  å¹³å‡ç­‰å¾…: {statistics.mean(acquire_times)*1000:.2f}ms")
                print(f"  æœ€å¤§ç­‰å¾…: {max(acquire_times)*1000:.2f}ms")
                
                # åˆ¤æ–­é™æµæ˜¯å¦ç”Ÿæ•ˆ
                rate_limit_working = abs(actual_qps - expected_qps) / expected_qps < 0.1  # è¯¯å·®<10%
                
                results.append({
                    "platform": platform,
                    "name": name,
                    "calls": calls,
                    "period": period,
                    "test_requests": test_requests,
                    "total_time": total_time,
                    "actual_qps": actual_qps,
                    "expected_qps": expected_qps,
                    "avg_acquire_time": statistics.mean(acquire_times),
                    "max_acquire_time": max(acquire_times),
                    "rate_limit_working": rate_limit_working,
                    "status": "âœ… æ­£å¸¸" if rate_limit_working else "âš ï¸ åå·®è¾ƒå¤§"
                })
            
            return {
                "test_name": "é™æµå™¨å‹åŠ›æµ‹è¯•",
                "status": "success",
                "results": results
            }
            
        except Exception as e:
            print(f"âŒ é™æµå™¨æµ‹è¯•å¤±è´¥: {e}")
            traceback.print_exc()
            return {"status": "failed", "error": str(e)}
    
    # ==================== æµ‹è¯•6: å¤§æ¶ˆæ¯å¤„ç†æµ‹è¯• ====================
    
    async def test_large_messages(self) -> Dict[str, Any]:
        """æµ‹è¯•6: å¤§æ¶ˆæ¯å¤„ç†æµ‹è¯•"""
        print("\n" + "=" * 100)
        print("æµ‹è¯•6: å¤§æ¶ˆæ¯å¤„ç†æµ‹è¯•")
        print("=" * 100)
        
        results = []
        
        for size in self.config["large_message_sizes"]:
            print(f"\næµ‹è¯•æ¶ˆæ¯å¤§å°: {size:6d} å­—ç¬¦...", end=" ")
            
            # ç”Ÿæˆå¤§æ¶ˆæ¯
            large_content = "æµ‹è¯•" * (size // 2)
            
            # æµ‹è¯•æ ¼å¼è½¬æ¢æ€§èƒ½
            try:
                from app.processors.formatter import kmarkdown_to_discord
                
                start = time.time()
                for _ in range(100):
                    kmarkdown_to_discord(large_content)
                convert_time = time.time() - start
                
                print(f"âœ… 100æ¬¡è½¬æ¢è€—æ—¶: {convert_time:.3f}s")
                
                results.append({
                    "size_chars": size,
                    "size_bytes": len(large_content.encode('utf-8')),
                    "iterations": 100,
                    "total_time": convert_time,
                    "avg_time_per_convert": convert_time / 100,
                    "status": "success"
                })
            except Exception as e:
                print(f"âŒ å¤±è´¥: {e}")
                results.append({
                    "size_chars": size,
                    "status": "failed",
                    "error": str(e)
                })
        
        return {
            "test_name": "å¤§æ¶ˆæ¯å¤„ç†æµ‹è¯•",
            "status": "success",
            "results": results
        }
    
    # ==================== æµ‹è¯•7: å†…å­˜æ³„æ¼æ£€æµ‹ ====================
    
    async def test_memory_leak(self) -> Dict[str, Any]:
        """æµ‹è¯•7: å†…å­˜æ³„æ¼æ£€æµ‹"""
        print("\n" + "=" * 100)
        print("æµ‹è¯•7: å†…å­˜æ³„æ¼æ£€æµ‹")
        print("=" * 100)
        
        print("æ‰§è¡Œé•¿æ—¶é—´å‹åŠ›æµ‹è¯•ä»¥æ£€æµ‹å†…å­˜æ³„æ¼...")
        print("æµ‹è¯•æ—¶é•¿: 60ç§’, é‡‡æ ·é—´éš”: 5ç§’\n")
        
        memory_samples = []
        start_memory = self.monitor.process.memory_info().rss / 1024 / 1024
        
        print(f"åˆå§‹å†…å­˜: {start_memory:.2f}MB")
        print(f"{'æ—¶é—´':>10s} {'å†…å­˜(MB)':>12s} {'å¢é•¿(MB)':>12s} {'CPU%':>8s}")
        print("-" * 50)
        
        test_duration = 60
        sample_interval = 5
        iterations = 0
        
        start_time = time.time()
        while time.time() - start_time < test_duration:
            # æ‰§è¡Œä¸€äº›è¯·æ±‚
            tasks = []
            for _ in range(50):
                endpoint = random.choice([
                    "/api/system/status",
                    "/api/accounts",
                    "/api/logs?limit=10"
                ])
                tasks.append(self.make_request("GET", endpoint))
            
            await asyncio.gather(*tasks, return_exceptions=True)
            iterations += 1
            
            # è®°å½•å†…å­˜
            current_memory = self.monitor.process.memory_info().rss / 1024 / 1024
            cpu_percent = self.monitor.process.cpu_percent()
            elapsed = time.time() - start_time
            
            memory_samples.append({
                "time": elapsed,
                "memory_mb": current_memory,
                "growth_mb": current_memory - start_memory,
                "cpu_percent": cpu_percent
            })
            
            print(f"{elapsed:>10.1f}s {current_memory:>12.2f} {current_memory - start_memory:>+12.2f} {cpu_percent:>8.1f}")
            
            await asyncio.sleep(sample_interval)
        
        final_memory = memory_samples[-1]["memory_mb"]
        total_growth = final_memory - start_memory
        
        # åˆ†æå†…å­˜å¢é•¿è¶‹åŠ¿
        if len(memory_samples) >= 3:
            # ç®€å•çº¿æ€§å›å½’æ£€æµ‹å¢é•¿è¶‹åŠ¿
            times = [s["time"] for s in memory_samples]
            memories = [s["memory_mb"] for s in memory_samples]
            
            # è®¡ç®—å¹³å‡å¢é•¿ç‡
            growth_rate = (memories[-1] - memories[0]) / (times[-1] - times[0])
            
            # åˆ¤æ–­æ˜¯å¦å¯èƒ½å­˜åœ¨å†…å­˜æ³„æ¼
            suspected_leak = growth_rate > 1.0  # æ¯ç§’å¢é•¿è¶…è¿‡1MB
            
            print(f"\næœ€ç»ˆå†…å­˜: {final_memory:.2f}MB")
            print(f"æ€»å¢é•¿: {total_growth:+.2f}MB")
            print(f"å¢é•¿ç‡: {growth_rate:.3f}MB/s")
            print(f"æ€»è¿­ä»£: {iterations}æ¬¡")
            
            if suspected_leak:
                print("âš ï¸  è­¦å‘Š: æ£€æµ‹åˆ°å¯èƒ½çš„å†…å­˜æ³„æ¼")
            else:
                print("âœ… å†…å­˜ä½¿ç”¨æ­£å¸¸")
        
        return {
            "test_name": "å†…å­˜æ³„æ¼æ£€æµ‹",
            "status": "success",
            "initial_memory_mb": start_memory,
            "final_memory_mb": final_memory,
            "total_growth_mb": total_growth,
            "growth_rate_mb_per_sec": growth_rate if 'growth_rate' in locals() else 0,
            "test_duration_sec": test_duration,
            "iterations": iterations,
            "suspected_leak": suspected_leak if 'suspected_leak' in locals() else False,
            "samples": memory_samples
        }
    
    # ==================== æµ‹è¯•8: æŒç»­è´Ÿè½½æµ‹è¯• ====================
    
    async def test_sustained_load(self) -> Dict[str, Any]:
        """æµ‹è¯•8: æŒç»­è´Ÿè½½æµ‹è¯•"""
        print("\n" + "=" * 100)
        print("æµ‹è¯•8: æŒç»­è´Ÿè½½æµ‹è¯•ï¼ˆæŒç»­è´Ÿè½½60ç§’ï¼‰")
        print("=" * 100)
        
        test_duration = 60
        concurrent_users = 20
        
        print(f"å¹¶å‘ç”¨æˆ·: {concurrent_users}")
        print(f"æµ‹è¯•æ—¶é•¿: {test_duration}ç§’")
        print(f"{'æ—¶é—´':>10s} {'è¯·æ±‚æ•°':>10s} {'æˆåŠŸç‡':>10s} {'å¹³å‡å»¶è¿Ÿ':>12s} {'QPS':>10s}")
        print("-" * 60)
        
        start_time = time.time()
        total_requests_before = self.total_requests
        samples = []
        
        while time.time() - start_time < test_duration:
            sample_start = time.time()
            requests_before = self.total_requests
            success_before = self.successful_requests
            
            # å‘é€ä¸€æ‰¹å¹¶å‘è¯·æ±‚
            tasks = []
            for _ in range(concurrent_users):
                endpoint = random.choice([
                    "/api/system/status",
                    "/api/accounts",
                    "/api/bots",
                    "/api/mappings",
                    "/api/logs?limit=10"
                ])
                tasks.append(self.make_request("GET", endpoint))
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ç»Ÿè®¡æœ¬æ‰¹æ¬¡
            sample_time = time.time() - sample_start
            sample_requests = self.total_requests - requests_before
            sample_success = self.successful_requests - success_before
            sample_success_rate = sample_success / sample_requests if sample_requests > 0 else 0
            
            recent_response_times = self.response_times[-(concurrent_users):]
            sample_avg_latency = statistics.mean(recent_response_times) if recent_response_times else 0
            sample_qps = sample_requests / sample_time if sample_time > 0 else 0
            
            elapsed = time.time() - start_time
            samples.append({
                "time": elapsed,
                "requests": sample_requests,
                "success_rate": sample_success_rate,
                "avg_latency": sample_avg_latency,
                "qps": sample_qps
            })
            
            print(f"{elapsed:>10.1f}s {sample_requests:>10d} {sample_success_rate:>9.1%} {sample_avg_latency*1000:>11.2f}ms {sample_qps:>10.1f}")
            
            await asyncio.sleep(1)
        
        total_test_time = time.time() - start_time
        total_test_requests = self.total_requests - total_requests_before
        overall_qps = total_test_requests / total_test_time
        overall_success_rate = sum(s["success_rate"] for s in samples) / len(samples) if samples else 0
        overall_avg_latency = sum(s["avg_latency"] for s in samples) / len(samples) if samples else 0
        
        print(f"\næŒç»­è´Ÿè½½æµ‹è¯•å®Œæˆ:")
        print(f"  æ€»è¯·æ±‚: {total_test_requests}")
        print(f"  å¹³å‡QPS: {overall_qps:.2f}")
        print(f"  å¹³å‡æˆåŠŸç‡: {overall_success_rate:.1%}")
        print(f"  å¹³å‡å»¶è¿Ÿ: {overall_avg_latency*1000:.2f}ms")
        
        return {
            "test_name": "æŒç»­è´Ÿè½½æµ‹è¯•",
            "status": "success",
            "duration_sec": total_test_time,
            "concurrent_users": concurrent_users,
            "total_requests": total_test_requests,
            "overall_qps": overall_qps,
            "overall_success_rate": overall_success_rate,
            "overall_avg_latency": overall_avg_latency,
            "samples": samples
        }
    
    # ==================== ä¸»æµ‹è¯•æµç¨‹ ====================
    
    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰å‹åŠ›æµ‹è¯•"""
        test_results["start_time"] = datetime.now().isoformat()
        
        # åˆå§‹åŒ–
        if not await self.setup():
            return False
        
        try:
            # æµ‹è¯•1: APIç«¯ç‚¹å…¨è¦†ç›–
            test_results["tests"]["api_endpoints"] = await self.test_all_api_endpoints()
            await asyncio.sleep(2)
            
            # æµ‹è¯•2: å¹¶å‘è¯·æ±‚å‹åŠ›æµ‹è¯•
            print("\n" + "=" * 100)
            print("æµ‹è¯•2: å¹¶å‘è¯·æ±‚å‹åŠ›æµ‹è¯•")
            print("=" * 100)
            
            concurrent_results = []
            for concurrent in self.config["concurrent_users"]:
                result = await self.test_concurrent_load(concurrent)
                concurrent_results.append(result)
                await asyncio.sleep(1)
            
            test_results["tests"]["concurrent_load"] = {
                "test_name": "å¹¶å‘è¯·æ±‚å‹åŠ›æµ‹è¯•",
                "results": concurrent_results
            }
            
            # æµ‹è¯•3: æ•°æ®åº“é«˜è´Ÿè½½æµ‹è¯•
            test_results["tests"]["database_stress"] = await self.test_database_stress()
            await asyncio.sleep(2)
            
            # æµ‹è¯•4: æ¶ˆæ¯é˜Ÿåˆ—æé™æµ‹è¯•
            test_results["tests"]["message_queue_extreme"] = await self.test_message_queue_extreme()
            await asyncio.sleep(2)
            
            # æµ‹è¯•5: é™æµå™¨å‹åŠ›æµ‹è¯•
            test_results["tests"]["rate_limiter_stress"] = await self.test_rate_limiter_stress()
            await asyncio.sleep(2)
            
            # æµ‹è¯•6: å¤§æ¶ˆæ¯å¤„ç†æµ‹è¯•
            test_results["tests"]["large_messages"] = await self.test_large_messages()
            await asyncio.sleep(2)
            
            # æµ‹è¯•7: å†…å­˜æ³„æ¼æ£€æµ‹
            test_results["tests"]["memory_leak"] = await self.test_memory_leak()
            await asyncio.sleep(2)
            
            # æµ‹è¯•8: æŒç»­è´Ÿè½½æµ‹è¯•
            test_results["tests"]["sustained_load"] = await self.test_sustained_load()
            
            # ç”Ÿæˆæ€»ç»“
            self.generate_summary()
            
            return True
            
        except Exception as e:
            print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            traceback.print_exc()
            return False
        finally:
            await self.teardown()
            test_results["end_time"] = datetime.now().isoformat()
    
    def generate_summary(self):
        """ç”Ÿæˆæµ‹è¯•æ€»ç»“"""
        print("\n" + "=" * 100)
        print("å‹åŠ›æµ‹è¯•æ€»ç»“")
        print("=" * 100)
        
        # æ€§èƒ½ç»Ÿè®¡
        perf_stats = self.monitor.get_stats()
        
        print(f"\nğŸ“Š è¯·æ±‚ç»Ÿè®¡:")
        print(f"  æ€»è¯·æ±‚æ•°: {self.total_requests}")
        print(f"  æˆåŠŸè¯·æ±‚: {self.successful_requests}")
        print(f"  å¤±è´¥è¯·æ±‚: {self.failed_requests}")
        print(f"  æˆåŠŸç‡: {self.successful_requests/self.total_requests*100:.2f}%")
        
        if self.response_times:
            print(f"\nâ±ï¸  å“åº”æ—¶é—´:")
            print(f"  å¹³å‡: {statistics.mean(self.response_times)*1000:.2f}ms")
            print(f"  æœ€å°: {min(self.response_times)*1000:.2f}ms")
            print(f"  æœ€å¤§: {max(self.response_times)*1000:.2f}ms")
            
            sorted_times = sorted(self.response_times)
            p50 = sorted_times[len(sorted_times)//2]
            p90 = sorted_times[int(len(sorted_times)*0.9)]
            p95 = sorted_times[int(len(sorted_times)*0.95)]
            p99 = sorted_times[int(len(sorted_times)*0.99)]
            
            print(f"  P50: {p50*1000:.2f}ms")
            print(f"  P90: {p90*1000:.2f}ms")
            print(f"  P95: {p95*1000:.2f}ms")
            print(f"  P99: {p99*1000:.2f}ms")
        
        if perf_stats:
            print(f"\nğŸ’» ç³»ç»Ÿèµ„æº:")
            print(f"  å†…å­˜ä½¿ç”¨:")
            print(f"    æœ€å°: {perf_stats['memory']['min_mb']:.2f}MB")
            print(f"    æœ€å¤§: {perf_stats['memory']['max_mb']:.2f}MB")
            print(f"    å¹³å‡: {perf_stats['memory']['avg_mb']:.2f}MB")
            print(f"    å¢é•¿: {perf_stats['memory']['growth_mb']:+.2f}MB")
            
            print(f"  CPUä½¿ç”¨:")
            print(f"    æœ€å°: {perf_stats['cpu']['min_percent']:.1f}%")
            print(f"    æœ€å¤§: {perf_stats['cpu']['max_percent']:.1f}%")
            print(f"    å¹³å‡: {perf_stats['cpu']['avg_percent']:.1f}%")
        
        if self.errors:
            print(f"\nâš ï¸  é”™è¯¯åˆ—è¡¨ (å‰10æ¡):")
            for i, error in enumerate(self.errors[:10], 1):
                print(f"  {i}. {error}")
        
        # ä¿å­˜æ‘˜è¦åˆ°ç»“æœ
        test_results["summary"] = {
            "total_requests": self.total_requests,
            "successful_requests": self.successful_requests,
            "failed_requests": self.failed_requests,
            "success_rate": self.successful_requests / self.total_requests if self.total_requests > 0 else 0,
            "response_time_stats": {
                "avg_ms": statistics.mean(self.response_times) * 1000 if self.response_times else 0,
                "min_ms": min(self.response_times) * 1000 if self.response_times else 0,
                "max_ms": max(self.response_times) * 1000 if self.response_times else 0,
                "p50_ms": sorted(self.response_times)[len(self.response_times)//2] * 1000 if self.response_times else 0,
                "p90_ms": sorted(self.response_times)[int(len(self.response_times)*0.9)] * 1000 if self.response_times else 0,
                "p99_ms": sorted(self.response_times)[int(len(self.response_times)*0.99)] * 1000 if self.response_times else 0,
            },
            "performance_stats": perf_stats,
            "error_count": len(self.errors)
        }


async def main():
    """ä¸»å‡½æ•°"""
    print("æ­£åœ¨åˆå§‹åŒ–å…¨é¢å‹åŠ›æµ‹è¯•...")
    
    runner = ComprehensiveStressTest(TEST_CONFIG)
    success = await runner.run_all_tests()
    
    if success:
        # ä¿å­˜JSONæŠ¥å‘Š
        report_path = Path(__file__).parent / "comprehensive_stress_test_report.json"
        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(test_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nâœ… JSONæŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        generate_markdown_report(test_results)
        
        print("\n" + "=" * 100)
        print("âœ… å…¨é¢å‹åŠ›æµ‹è¯•å®Œæˆ!")
        print("=" * 100)
        
        return 0
    else:
        print("\nâŒ å‹åŠ›æµ‹è¯•å¤±è´¥")
        return 1


def generate_markdown_report(results: Dict[str, Any]):
    """ç”Ÿæˆè¯¦ç»†çš„Markdownæµ‹è¯•æŠ¥å‘Š"""
    report_path = Path(__file__).parent / "å‹åŠ›æµ‹è¯•è¯¦ç»†æŠ¥å‘Š.md"
    
    with open(report_path, "w", encoding="utf-8") as f:
        f.write("# KOOKæ¶ˆæ¯è½¬å‘ç³»ç»Ÿ - å…¨é¢å‹åŠ›æµ‹è¯•æŠ¥å‘Š\n\n")
        f.write(f"**æµ‹è¯•å¼€å§‹æ—¶é—´**: {results['start_time']}\n\n")
        f.write(f"**æµ‹è¯•ç»“æŸæ—¶é—´**: {results['end_time']}\n\n")
        f.write("---\n\n")
        
        # ç³»ç»Ÿä¿¡æ¯
        f.write("## ğŸ–¥ï¸ æµ‹è¯•ç¯å¢ƒ\n\n")
        f.write("| é¡¹ç›® | å€¼ |\n")
        f.write("|------|----|\n")
        for key, value in results["system_info"].items():
            f.write(f"| {key} | {value} |\n")
        f.write("\n---\n\n")
        
        # æµ‹è¯•æ€»ç»“
        if "summary" in results:
            summary = results["summary"]
            f.write("## ğŸ“Š æµ‹è¯•æ€»ç»“\n\n")
            f.write(f"- **æ€»è¯·æ±‚æ•°**: {summary['total_requests']:,}\n")
            f.write(f"- **æˆåŠŸè¯·æ±‚**: {summary['successful_requests']:,}\n")
            f.write(f"- **å¤±è´¥è¯·æ±‚**: {summary['failed_requests']:,}\n")
            f.write(f"- **æˆåŠŸç‡**: {summary['success_rate']*100:.2f}%\n\n")
            
            f.write("### å“åº”æ—¶é—´ç»Ÿè®¡\n\n")
            rt_stats = summary["response_time_stats"]
            f.write("| æŒ‡æ ‡ | å€¼ |\n")
            f.write("|------|----|\n")
            f.write(f"| å¹³å‡ | {rt_stats['avg_ms']:.2f}ms |\n")
            f.write(f"| æœ€å° | {rt_stats['min_ms']:.2f}ms |\n")
            f.write(f"| æœ€å¤§ | {rt_stats['max_ms']:.2f}ms |\n")
            f.write(f"| P50 | {rt_stats['p50_ms']:.2f}ms |\n")
            f.write(f"| P90 | {rt_stats['p90_ms']:.2f}ms |\n")
            f.write(f"| P99 | {rt_stats['p99_ms']:.2f}ms |\n")
            f.write("\n")
            
            if "performance_stats" in summary and summary["performance_stats"]:
                perf = summary["performance_stats"]
                f.write("### ç³»ç»Ÿèµ„æºä½¿ç”¨\n\n")
                
                if "memory" in perf:
                    f.write("**å†…å­˜ä½¿ç”¨**:\n")
                    f.write(f"- æœ€å°: {perf['memory']['min_mb']:.2f}MB\n")
                    f.write(f"- æœ€å¤§: {perf['memory']['max_mb']:.2f}MB\n")
                    f.write(f"- å¹³å‡: {perf['memory']['avg_mb']:.2f}MB\n")
                    f.write(f"- å¢é•¿: {perf['memory']['growth_mb']:+.2f}MB\n\n")
                
                if "cpu" in perf:
                    f.write("**CPUä½¿ç”¨**:\n")
                    f.write(f"- æœ€å°: {perf['cpu']['min_percent']:.1f}%\n")
                    f.write(f"- æœ€å¤§: {perf['cpu']['max_percent']:.1f}%\n")
                    f.write(f"- å¹³å‡: {perf['cpu']['avg_percent']:.1f}%\n\n")
        
        f.write("---\n\n")
        
        # è¯¦ç»†æµ‹è¯•ç»“æœ
        f.write("## ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ\n\n")
        
        for test_name, test_data in results["tests"].items():
            test_title = test_data.get("test_name", test_name)
            f.write(f"### {test_title}\n\n")
            
            if test_data.get("status") == "failed":
                f.write(f"âŒ **çŠ¶æ€**: å¤±è´¥\n\n")
                f.write(f"**é”™è¯¯**: {test_data.get('error', 'Unknown')}\n\n")
                continue
            
            f.write(f"âœ… **çŠ¶æ€**: æˆåŠŸ\n\n")
            
            # å¤„ç†ä¸åŒç±»å‹çš„ç»“æœ
            if "results" in test_data:
                results_data = test_data["results"]
                
                if isinstance(results_data, list) and results_data:
                    # è¡¨æ ¼æ ¼å¼
                    first_item = results_data[0]
                    if isinstance(first_item, dict):
                        keys = list(first_item.keys())
                        
                        # å†™è¡¨å¤´
                        f.write("| " + " | ".join(keys) + " |\n")
                        f.write("|" + "|".join(["---"] * len(keys)) + "|\n")
                        
                        # å†™æ•°æ®
                        for item in results_data[:20]:  # é™åˆ¶æ˜¾ç¤ºå‰20è¡Œ
                            values = []
                            for k in keys:
                                v = item.get(k, "")
                                if isinstance(v, float):
                                    values.append(f"{v:.3f}")
                                else:
                                    values.append(str(v))
                            f.write("| " + " | ".join(values) + " |\n")
                        
                        if len(results_data) > 20:
                            f.write(f"\n*ï¼ˆä»…æ˜¾ç¤ºå‰20æ¡ï¼Œå…±{len(results_data)}æ¡ï¼‰*\n")
                
                elif isinstance(results_data, dict):
                    # é”®å€¼å¯¹æ ¼å¼
                    for key, value in results_data.items():
                        if isinstance(value, dict):
                            f.write(f"\n**{key}**:\n")
                            for k, v in value.items():
                                f.write(f"- {k}: {v}\n")
                        else:
                            f.write(f"- **{key}**: {value}\n")
            
            # å¤„ç†å…¶ä»–å­—æ®µ
            for key in ["batch_results", "capacity_test", "samples"]:
                if key in test_data:
                    if key == "samples" and len(test_data[key]) > 10:
                        f.write(f"\n*{key}: {len(test_data[key])}ä¸ªæ ·æœ¬ï¼ˆç•¥ï¼‰*\n")
                    else:
                        f.write(f"\n**{key}**: {test_data[key]}\n")
            
            f.write("\n")
        
        f.write("---\n\n")
        f.write(f"**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"\n*æ­¤æŠ¥å‘Šç”± KOOKæ¶ˆæ¯è½¬å‘ç³»ç»Ÿå‹åŠ›æµ‹è¯•å·¥å…·è‡ªåŠ¨ç”Ÿæˆ*\n")
    
    print(f"âœ… MarkdownæŠ¥å‘Šå·²ä¿å­˜: {report_path}")


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        traceback.print_exc()
        sys.exit(1)
