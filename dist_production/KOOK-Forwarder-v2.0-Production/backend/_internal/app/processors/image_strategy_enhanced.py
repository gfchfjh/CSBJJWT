"""
å›¾ç‰‡å¤„ç†æ™ºèƒ½ç­–ç•¥ - âœ… P0-7ä¼˜åŒ–å®Œæˆ: 3æ­¥Fallbacké™çº§æœºåˆ¶
"""
import aiohttp
import asyncio
from typing import Dict, Optional, Tuple
from pathlib import Path
from ..utils.logger import logger
from ..config import settings


class ImageStrategyEnhanced:
    """
    âœ… P0-7ä¼˜åŒ–: å›¾ç‰‡å¤„ç†æ™ºèƒ½Fallbackç­–ç•¥
    
    ä¸‰æ­¥é™çº§æœºåˆ¶ï¼š
    1. ç›´ä¼ æ¨¡å¼ï¼šéªŒè¯åŸå§‹URLå¯è®¿é—®æ€§ï¼ŒæˆåŠŸåˆ™ç›´ä¼ 
    2. å›¾åºŠæ¨¡å¼ï¼šåŸå§‹URLä¸å¯ç”¨æ—¶ï¼Œä¸‹è½½å¹¶ä¸Šä¼ åˆ°æœ¬åœ°å›¾åºŠ
    3. æœ¬åœ°æ¨¡å¼ï¼šå›¾åºŠä¹Ÿå¤±è´¥æ—¶ï¼Œä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿç­‰å¾…åç»­é‡è¯•
    """
    
    def __init__(self):
        self.stats = {
            "direct_success": 0,      # ç›´ä¼ æˆåŠŸæ¬¡æ•°
            "imgbed_success": 0,      # å›¾åºŠæˆåŠŸæ¬¡æ•°
            "local_fallback": 0,      # æœ¬åœ°é™çº§æ¬¡æ•°
            "total_failures": 0       # å®Œå…¨å¤±è´¥æ¬¡æ•°
        }
        
        logger.info("âœ… P0-7: å›¾ç‰‡æ™ºèƒ½Fallbackç­–ç•¥å·²åˆå§‹åŒ–")
    
    async def process_with_smart_fallback(
        self,
        url: str,
        cookies: dict = None,
        referer: str = "https://www.kookapp.cn"
    ) -> Dict[str, any]:
        """
        âœ… P0-7æ ¸å¿ƒ: æ™ºèƒ½Fallbackå¤„ç†å›¾ç‰‡
        
        å¤„ç†æµç¨‹ï¼š
        1ï¸âƒ£ å°è¯•éªŒè¯åŸå§‹URL â†’ æˆåŠŸåˆ™ç›´ä¼ 
        2ï¸âƒ£ å¤±è´¥åˆ™ä¸‹è½½å¹¶ä¸Šä¼ åˆ°æœ¬åœ°å›¾åºŠ â†’ è¿”å›å›¾åºŠURL
        3ï¸âƒ£ å›¾åºŠä¹Ÿå¤±è´¥åˆ™ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ â†’ ç­‰å¾…åç»­é‡è¯•
        
        Args:
            url: å›¾ç‰‡åŸå§‹URL
            cookies: Cookieå­—å…¸ï¼ˆç”¨äºä¸‹è½½é˜²ç›—é“¾å›¾ç‰‡ï¼‰
            referer: Refererå¤´
            
        Returns:
            {
                "success": bool,           # æ˜¯å¦æˆåŠŸ
                "method": str,             # ä½¿ç”¨çš„æ–¹æ³•ï¼šdirect/imgbed/local
                "original_url": str,       # åŸå§‹URL
                "accessible_url": str,     # å¯è®¿é—®çš„URLï¼ˆç›´ä¼ æˆ–å›¾åºŠï¼‰
                "local_path": str,         # æœ¬åœ°è·¯å¾„ï¼ˆé™çº§æ—¶ï¼‰
                "fallback_count": int,     # Fallbackæ¬¡æ•°ï¼ˆ0/1/2ï¼‰
                "error": str               # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            }
        """
        result = {
            "success": False,
            "method": None,
            "original_url": url,
            "accessible_url": None,
            "local_path": None,
            "fallback_count": 0,
            "error": None
        }
        
        logger.info(f"ğŸ–¼ï¸ P0-7: å¼€å§‹æ™ºèƒ½Fallbackå¤„ç†å›¾ç‰‡: {url[:50]}...")
        
        # ======= æ­¥éª¤1: å°è¯•éªŒè¯åŸå§‹URLå¯è®¿é—®æ€§ =======
        logger.info("1ï¸âƒ£ æ­¥éª¤1: éªŒè¯åŸå§‹URLå¯è®¿é—®æ€§...")
        
        is_accessible = await self._test_url_accessibility(url, cookies, referer)
        
        if is_accessible:
            logger.info("âœ… åŸå§‹URLå¯ç›´æ¥è®¿é—®ï¼Œä½¿ç”¨ç›´ä¼ æ¨¡å¼")
            result["success"] = True
            result["method"] = "direct"
            result["accessible_url"] = url
            result["fallback_count"] = 0
            
            self.stats["direct_success"] += 1
            return result
        
        logger.warning("âš ï¸ åŸå§‹URLä¸å¯è®¿é—®ï¼Œè¿›å…¥Fallbackæ­¥éª¤2")
        result["fallback_count"] += 1
        
        # ======= æ­¥éª¤2: ä¸‹è½½å¹¶ä¸Šä¼ åˆ°æœ¬åœ°å›¾åºŠ =======
        logger.info("2ï¸âƒ£ æ­¥éª¤2: ä¸‹è½½å›¾ç‰‡å¹¶ä¸Šä¼ åˆ°æœ¬åœ°å›¾åºŠ...")
        
        # ä¸‹è½½å›¾ç‰‡
        image_data = await self._download_image_safe(url, cookies, referer)
        
        if image_data:
            # ä¸Šä¼ åˆ°æœ¬åœ°å›¾åºŠ
            imgbed_url = await self._upload_to_local_imgbed(image_data, url)
            
            if imgbed_url:
                logger.info("âœ… å›¾åºŠæ¨¡å¼æˆåŠŸ")
                result["success"] = True
                result["method"] = "imgbed"
                result["accessible_url"] = imgbed_url
                result["fallback_count"] = 1
                
                self.stats["imgbed_success"] += 1
                return result
            else:
                logger.warning("âš ï¸ ä¸Šä¼ åˆ°å›¾åºŠå¤±è´¥ï¼Œè¿›å…¥Fallbackæ­¥éª¤3")
                result["fallback_count"] += 1
        else:
            logger.warning("âš ï¸ ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼Œè¿›å…¥Fallbackæ­¥éª¤3")
            result["fallback_count"] += 1
        
        # ======= æ­¥éª¤3: ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ =======
        logger.info("3ï¸âƒ£ æ­¥éª¤3: ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼ˆç­‰å¾…åç»­é‡è¯•ï¼‰...")
        
        if image_data:
            local_path = await self._save_to_local_file(image_data, url)
            
            if local_path:
                logger.info("âš ï¸ æœ¬åœ°é™çº§æ¨¡å¼ï¼ˆå›¾ç‰‡å·²ä¿å­˜ï¼‰")
                result["success"] = True  # æ ‡è®°ä¸ºæˆåŠŸï¼ˆè™½ç„¶æ˜¯é™çº§ï¼‰
                result["method"] = "local"
                result["local_path"] = local_path
                result["fallback_count"] = 2
                result["error"] = "å›¾ç‰‡æš‚å­˜æœ¬åœ°ï¼Œç­‰å¾…åç»­é‡è¯•ä¸Šä¼ "
                
                self.stats["local_fallback"] += 1
                return result
        
        # ======= å…¨éƒ¨å¤±è´¥ =======
        logger.error("âŒ P0-7: æ‰€æœ‰Fallbackæ­¥éª¤éƒ½å¤±è´¥")
        result["success"] = False
        result["fallback_count"] = 3
        result["error"] = "åŸå§‹URLä¸å¯è®¿é—®ã€ä¸‹è½½å¤±è´¥ã€å›¾åºŠå¤±è´¥ã€æœ¬åœ°ä¿å­˜ä¹Ÿå¤±è´¥"
        
        self.stats["total_failures"] += 1
        return result
    
    async def _test_url_accessibility(
        self,
        url: str,
        cookies: dict = None,
        referer: str = None,
        timeout: int = 5
    ) -> bool:
        """
        æµ‹è¯•URLæ˜¯å¦å¯ç›´æ¥è®¿é—®
        
        Args:
            url: å›¾ç‰‡URL
            cookies: Cookieå­—å…¸
            referer: Refererå¤´
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            æ˜¯å¦å¯è®¿é—®
        """
        try:
            headers = {}
            if referer:
                headers['Referer'] = referer
            if cookies:
                # æ„å»ºCookieå¤´
                cookie_str = "; ".join([f"{k}={v}" for k, v in cookies.items()])
                headers['Cookie'] = cookie_str
            
            async with aiohttp.ClientSession() as session:
                async with session.head(
                    url,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=timeout),
                    allow_redirects=True
                ) as response:
                    # 200-299éƒ½è®¤ä¸ºå¯è®¿é—®
                    is_accessible = 200 <= response.status < 300
                    
                    if is_accessible:
                        logger.debug(f"âœ… URLå¯è®¿é—®: {url[:50]}... (HTTP {response.status})")
                    else:
                        logger.debug(f"âŒ URLä¸å¯è®¿é—®: {url[:50]}... (HTTP {response.status})")
                    
                    return is_accessible
        
        except asyncio.TimeoutError:
            logger.debug(f"âŒ URLè®¿é—®è¶…æ—¶: {url[:50]}...")
            return False
        except Exception as e:
            logger.debug(f"âŒ URLè®¿é—®å¤±è´¥: {url[:50]}... - {str(e)}")
            return False
    
    async def _download_image_safe(
        self,
        url: str,
        cookies: dict = None,
        referer: str = None,
        max_size_mb: int = 50
    ) -> Optional[bytes]:
        """
        å®‰å…¨åœ°ä¸‹è½½å›¾ç‰‡ï¼ˆå¸¦é˜²ç›—é“¾å¤„ç†ï¼‰
        
        Args:
            url: å›¾ç‰‡URL
            cookies: Cookieå­—å…¸
            referer: Refererå¤´
            max_size_mb: æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
            
        Returns:
            å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            if referer:
                headers['Referer'] = referer
            
            if cookies:
                cookie_str = "; ".join([f"{k}={v}" for k, v in cookies.items()])
                headers['Cookie'] = cookie_str
            
            async with aiohttp.ClientSession() as session:
                async with session.get(
                    url,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status != 200:
                        logger.warning(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥: HTTP {response.status}")
                        return None
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    content_length = response.headers.get('Content-Length')
                    if content_length:
                        size_mb = int(content_length) / (1024 * 1024)
                        if size_mb > max_size_mb:
                            logger.warning(f"å›¾ç‰‡è¿‡å¤§: {size_mb:.2f}MB > {max_size_mb}MB")
                            return None
                    
                    # è¯»å–æ•°æ®
                    image_data = await response.read()
                    
                    logger.info(f"âœ… å›¾ç‰‡ä¸‹è½½æˆåŠŸ: {len(image_data) / 1024:.2f}KB")
                    return image_data
        
        except asyncio.TimeoutError:
            logger.error("ä¸‹è½½å›¾ç‰‡è¶…æ—¶")
            return None
        except Exception as e:
            logger.error(f"ä¸‹è½½å›¾ç‰‡å¼‚å¸¸: {str(e)}")
            return None
    
    async def _upload_to_local_imgbed(
        self,
        image_data: bytes,
        original_url: str
    ) -> Optional[str]:
        """
        ä¸Šä¼ å›¾ç‰‡åˆ°æœ¬åœ°å›¾åºŠ
        
        Args:
            image_data: å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
            original_url: åŸå§‹URLï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼‰
            
        Returns:
            å›¾åºŠURLï¼Œå¤±è´¥è¿”å›None
        """
        try:
            from ..processors.image import image_processor
            
            # ç”Ÿæˆæ–‡ä»¶å
            import hashlib
            url_hash = hashlib.md5(original_url.encode()).hexdigest()
            filename = f"{url_hash}.jpg"
            
            # ä¿å­˜åˆ°å›¾åºŠç›®å½•
            imgbed_dir = Path(settings.data_dir) / 'images'
            imgbed_dir.mkdir(parents=True, exist_ok=True)
            
            file_path = imgbed_dir / filename
            file_path.write_bytes(image_data)
            
            # ç”Ÿæˆå›¾åºŠURLï¼ˆå¸¦Tokenï¼‰
            import secrets
            token = secrets.token_urlsafe(16)
            
            # ä¿å­˜Tokenåˆ°æ•°æ®åº“ï¼ˆæœ‰æ•ˆæœŸ2å°æ—¶ï¼‰
            from ..queue.redis_client import redis_queue
            await redis_queue.set(
                f"img_token:{filename}",
                token,
                expire=7200  # 2å°æ—¶
            )
            
            # æ„å»ºå®Œæ•´URL
            imgbed_url = f"http://127.0.0.1:{settings.image_server_port}/images/{filename}?token={token}"
            
            logger.info(f"âœ… ä¸Šä¼ åˆ°æœ¬åœ°å›¾åºŠæˆåŠŸ: {filename}")
            return imgbed_url
        
        except Exception as e:
            logger.error(f"ä¸Šä¼ åˆ°æœ¬åœ°å›¾åºŠå¤±è´¥: {str(e)}")
            return None
    
    async def _save_to_local_file(
        self,
        image_data: bytes,
        original_url: str
    ) -> Optional[str]:
        """
        ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼ˆæœ€åçš„é™çº§æ–¹æ¡ˆï¼‰
        
        Args:
            image_data: å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
            original_url: åŸå§‹URL
            
        Returns:
            æœ¬åœ°æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        try:
            # åˆ›å»ºå¾…é‡è¯•ç›®å½•
            pending_dir = Path(settings.data_dir) / 'images_pending'
            pending_dir.mkdir(parents=True, exist_ok=True)
            
            # ç”Ÿæˆæ–‡ä»¶å
            import hashlib
            import time
            url_hash = hashlib.md5(original_url.encode()).hexdigest()
            timestamp = int(time.time())
            filename = f"{timestamp}_{url_hash}.jpg"
            
            file_path = pending_dir / filename
            file_path.write_bytes(image_data)
            
            logger.info(f"âš ï¸ å›¾ç‰‡å·²ä¿å­˜åˆ°æœ¬åœ°å¾…é‡è¯•: {file_path}")
            
            # è®°å½•å…ƒæ•°æ®åˆ°Redisï¼ˆç”¨äºåç»­é‡è¯•ï¼‰
            from ..queue.redis_client import redis_queue
            await redis_queue.set(
                f"img_pending:{filename}",
                original_url,
                expire=86400  # 1å¤©
            )
            
            return str(file_path)
        
        except Exception as e:
            logger.error(f"ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
    
    def get_stats(self) -> Dict:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            {
                "direct_success": int,
                "imgbed_success": int,
                "local_fallback": int,
                "total_failures": int,
                "total_processed": int,
                "success_rate": float
            }
        """
        total_processed = (
            self.stats["direct_success"] +
            self.stats["imgbed_success"] +
            self.stats["local_fallback"] +
            self.stats["total_failures"]
        )
        
        success_count = (
            self.stats["direct_success"] +
            self.stats["imgbed_success"] +
            self.stats["local_fallback"]
        )
        
        success_rate = (success_count / total_processed * 100) if total_processed > 0 else 0
        
        return {
            **self.stats,
            "total_processed": total_processed,
            "success_rate": round(success_rate, 2)
        }


# åˆ›å»ºå…¨å±€å®ä¾‹
image_strategy_enhanced = ImageStrategyEnhanced()
