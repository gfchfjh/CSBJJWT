"""
KOOKæ¶ˆæ¯æŠ“å–å™¨ - å®Œæ•´å®ç°ç‰ˆ
ä½¿ç”¨Playwrightç›‘å¬KOOK WebSocketæ¶ˆæ¯
"""
from playwright.async_api import async_playwright, Browser, Page, BrowserContext
from playwright.sync_api import sync_playwright
import concurrent.futures
import asyncio
import json
import random
from typing import Dict, List, Optional, Callable
from pathlib import Path
from ..config import settings
from ..utils.logger import logger
from ..database import db
from ..queue.redis_client import redis_queue
import time


class KookScraper:
    """KOOKæ¶ˆæ¯æŠ“å–å™¨ - å®Œæ•´å®ç°"""
    
    def __init__(self, account_id: int):
        self.account_id = account_id
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        self.is_running = False
        self.reconnect_count = 0
        self.max_reconnect = 5
        self.message_handlers: List[Callable] = []
        
    async def start(self):
        """å¯åŠ¨æŠ“å–å™¨"""
        try:
            logger.info(f"[Scraper-{self.account_id}] æ­£åœ¨å¯åŠ¨...")
            
            # Windowså…¼å®¹æ€§ï¼šä½¿ç”¨åŒæ­¥Playwrighté¿å…asyncioå­è¿›ç¨‹é—®é¢˜
            import sys
            use_sync = sys.platform == "win32"
            
            if use_sync:
                logger.info(f"[Scraper-{self.account_id}] ä½¿ç”¨åŒæ­¥Playwrightï¼ˆWindowså…¼å®¹æ¨¡å¼ï¼‰")
                # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ç‰ˆæœ¬
                loop = asyncio.get_event_loop()
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    await loop.run_in_executor(executor, self._run_sync_playwright)
                return
            
            async with async_playwright() as p:
                # âœ… åæ£€æµ‹å¢å¼º1: å¯åŠ¨æµè§ˆå™¨ï¼ˆæœ‰ç•Œé¢æ¨¡å¼ + å®Œæ•´å‚æ•°ï¼‰
                self.browser = await p.chromium.launch(
                    headless=False,  # ä½¿ç”¨æœ‰ç•Œé¢æ¨¡å¼ï¼Œæ›´éš¾è¢«æ£€æµ‹
                    args=[
                        '--no-sandbox',
                        '--disable-setuid-sandbox',
                        '--disable-dev-shm-usage',
                        '--disable-blink-features=AutomationControlled',  # å…³é”®ï¼šéšè—è‡ªåŠ¨åŒ–ç‰¹å¾
                        '--disable-automation',  # ç¦ç”¨è‡ªåŠ¨åŒ–æ‰©å±•
                        '--disable-infobars',  # éšè—ä¿¡æ¯æ 
                        '--no-first-run',
                        '--no-default-browser-check',
                        '--disable-background-timer-throttling',
                        '--disable-backgrounding-occluded-windows',
                        '--disable-renderer-backgrounding',
                        '--disable-features=IsolateOrigins,site-per-process',
                        '--window-size=1920,1080',
                        '--start-maximized',
                    ],
                    # æ·»åŠ é¢å¤–çš„å¯åŠ¨é€‰é¡¹
                    slow_mo=random.randint(50, 150)  # éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·
                )
                
                # âœ… åæ£€æµ‹å¢å¼º2: åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡ï¼ˆå®Œæ•´é…ç½® + éšæœºUser-Agentï¼‰
                user_agents = [
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
                    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
                    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                ]
                
                self.context = await self.browser.new_context(
                    viewport={'width': 1920, 'height': 1080},
                    user_agent=random.choice(user_agents),  # éšæœºUser-Agent
                    locale='zh-CN',
                    timezone_id='Asia/Shanghai',
                    permissions=['geolocation', 'notifications'],
                    device_scale_factor=1,
                    has_touch=False,
                    color_scheme='light',
                    # é¢å¤–çš„æŒ‡çº¹ä¼ªè£…
                    extra_http_headers={
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                        'DNT': '1',
                    }
                )
                
                # âœ… åæ£€æµ‹å¢å¼º3: æ³¨å…¥JavaScriptåæ£€æµ‹è„šæœ¬
                await self.context.add_init_script("""
                    // åˆ é™¤webdriveræ ‡è®°
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => false
                    });
                    
                    // ä¼ªè£…chromeå¯¹è±¡
                    window.chrome = {
                        runtime: {},
                        loadTimes: function() {},
                        csi: function() {},
                        app: {}
                    };
                    
                    // ä¼ªè£…æƒé™API
                    const originalQuery = window.navigator.permissions.query;
                    window.navigator.permissions.query = (parameters) => (
                        parameters.name === 'notifications' ?
                            Promise.resolve({ state: Notification.permission }) :
                            originalQuery(parameters)
                    );
                    
                    // ä¼ªè£…è¯­è¨€
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-CN', 'zh', 'en-US', 'en']
                    });
                    
                    // ä¼ªè£…æ’ä»¶æ•°é‡ï¼ˆæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ï¼‰
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });
                    
                    // ä¼ªè£…å¹³å°
                    Object.defineProperty(navigator, 'platform', {
                        get: () => 'Win32'
                    });
                    
                    // ä¼ªè£…ç¡¬ä»¶å¹¶å‘æ•°
                    Object.defineProperty(navigator, 'hardwareConcurrency', {
                        get: () => 8
                    });
                    
                    // ä¼ªè£…è®¾å¤‡å†…å­˜
                    Object.defineProperty(navigator, 'deviceMemory', {
                        get: () => 8
                    });
                """)
                
                # âœ… åæ£€æµ‹å¢å¼º3: æ³¨å…¥JavaScriptåæ£€æµ‹è„šæœ¬
                await self.context.add_init_script("""
                    // åˆ é™¤webdriveræ ‡è®°
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => false
                    });
                    
                    // ä¼ªè£…chromeå¯¹è±¡
                    window.chrome = {
                        runtime: {},
                        loadTimes: function() {},
                        csi: function() {},
                        app: {}
                    };
                    
                    // ä¼ªè£…æƒé™API
                    const originalQuery = window.navigator.permissions.query;
                    window.navigator.permissions.query = (parameters) => (
                        parameters.name === 'notifications' ?
                            Promise.resolve({ state: Notification.permission }) :
                            originalQuery(parameters)
                    );
                    
                    // ä¼ªè£…è¯­è¨€
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-CN', 'zh', 'en-US', 'en']
                    });
                    
                    // ä¼ªè£…æ’ä»¶æ•°é‡ï¼ˆæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ï¼‰
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });
                    
                    // ä¼ªè£…å¹³å°
                    Object.defineProperty(navigator, 'platform', {
                        get: () => 'Win32'
                    });
                    
                    // ä¼ªè£…ç¡¬ä»¶å¹¶å‘æ•°
                    Object.defineProperty(navigator, 'hardwareConcurrency', {
                        get: () => 8
                    });
                    
                    // ä¼ªè£…è®¾å¤‡å†…å­˜
                    Object.defineProperty(navigator, 'deviceMemory', {
                        get: () => 8
                    });
                """)

                # åŠ è½½Cookieï¼ˆå¦‚æœæœ‰ï¼‰

                # âœ… åæ£€æµ‹å¢å¼º: æ³¨å…¥JavaScriptåæ£€æµ‹è„šæœ¬
                await self.context.add_init_script("""
                    // åˆ é™¤webdriveræ ‡è®°
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => false
                    });
                    
                    // ä¼ªè£…chromeå¯¹è±¡
                    window.chrome = {
                        runtime: {},
                        loadTimes: function() {},
                        csi: function() {},
                        app: {}
                    };
                    
                    // ä¼ªè£…æƒé™API
                    const originalQuery = window.navigator.permissions.query;
                    window.navigator.permissions.query = (parameters) => (
                        parameters.name === 'notifications' ?
                            Promise.resolve({ state: Notification.permission }) :
                            originalQuery(parameters)
                    );
                    
                    // ä¼ªè£…è¯­è¨€
                    Object.defineProperty(navigator, 'languages', {
                        get: () => ['zh-CN', 'zh', 'en-US', 'en']
                    });
                    
                    // ä¼ªè£…æ’ä»¶
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5]
                    });
                    
                    // ä¼ªè£…å¹³å°
                    Object.defineProperty(navigator, 'platform', {
                        get: () => 'Win32'
                    });
                    
                    // ä¼ªè£…ç¡¬ä»¶ä¿¡æ¯
                    Object.defineProperty(navigator, 'hardwareConcurrency', {
                        get: () => 8
                    });
                    
                    Object.defineProperty(navigator, 'deviceMemory', {
                        get: () => 8
                    });
                """)

                cookies = self.load_cookies()
                if cookies:
                    await self.context.add_cookies(cookies)
                    logger.info(f"[Scraper-{self.account_id}] å·²åŠ è½½Cookie")
                
                # åˆ›å»ºé¡µé¢
                self.page = await self.context.new_page()
                
                # ç›‘å¬WebSocket
                self.page.on('websocket', self.handle_websocket)
                
                # ç›‘å¬æ§åˆ¶å°æ—¥å¿—ï¼ˆè°ƒè¯•ç”¨ï¼‰
                self.page.on('console', lambda msg: 
                    logger.debug(f"[Browser Console] {msg.text}")
                )
                
                # âœ… åæ£€æµ‹å¢å¼º4: åˆ†æ­¥è®¿é—®ï¼Œæ¨¡æ‹ŸçœŸå®ç”¨æˆ·è¡Œä¸º
                logger.info(f"[Scraper-{self.account_id}] æ­£åœ¨è®¿é—®KOOK...")
                
                # å…ˆè®¿é—®é¦–é¡µï¼ˆæ¨¡æ‹ŸçœŸå®ç”¨æˆ·ï¼‰
                await self.page.goto('https://www.kookapp.cn', wait_until='networkidle')
                await asyncio.sleep(random.uniform(1.5, 3.5))  # éšæœºå»¶è¿Ÿ
                
                # âœ… åæ£€æµ‹å¢å¼º5: æ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼ˆé¼ æ ‡ç§»åŠ¨å’Œæ»šåŠ¨ï¼‰
                await self.simulate_human_behavior()
                
                # å†è®¿é—®appé¡µé¢
                await self.page.goto('https://www.kookapp.cn/app', wait_until='networkidle')
                
                # âœ… åæ£€æµ‹å¢å¼º6: éšæœºç­‰å¾…æ—¶é—´
                await asyncio.sleep(random.uniform(2, 4))
                
                # æ£€æŸ¥ç™»å½•çŠ¶æ€
                is_logged_in = await self.check_login_status()
                
                if not is_logged_in:
                    logger.warning(f"[Scraper-{self.account_id}] æœªç™»å½•ï¼Œå¼€å§‹ç™»å½•æµç¨‹...")
                    
                    # è·å–è´¦å·ä¿¡æ¯
                    account = db.execute(
                        "SELECT * FROM accounts WHERE id = ?",
                        (self.account_id,)
                    ).fetchone()
                    
                    if not account:
                        raise Exception("è´¦å·ä¸å­˜åœ¨")
                    
                    # å°è¯•ç™»å½•
                    if account['password_encrypted']:
                        # è´¦å·å¯†ç ç™»å½•
                        success = await self.login_with_password(
                            account['email'],
                            self.decrypt_password(account['password_encrypted'])
                        )
                    else:
                        # Cookieåº”è¯¥å·²åŠ è½½ï¼Œå¦‚æœè¿˜æœªç™»å½•è¯´æ˜Cookieå¤±æ•ˆ
                        raise Exception("Cookieå·²å¤±æ•ˆï¼Œè¯·é‡æ–°ç™»å½•")
                    
                    if not success:
                        raise Exception("ç™»å½•å¤±è´¥")
                
                logger.info(f"[Scraper-{self.account_id}] ç™»å½•æˆåŠŸï¼Œå¼€å§‹ç›‘å¬æ¶ˆæ¯...")
                
                # æ›´æ–°è´¦å·çŠ¶æ€
                db.execute(
                    "UPDATE accounts SET status = 'online', last_active = CURRENT_TIMESTAMP WHERE id = ?",
                    (self.account_id,)
                )
                db.commit()
                
                # ä¿æŒè¿è¡Œ
                self.is_running = True
                activity_counter = 0
                while self.is_running:
                    await asyncio.sleep(1)
                    activity_counter += 1
                    
                    # âœ… åæ£€æµ‹å¢å¼º7: å®šæœŸæ¨¡æ‹Ÿç”¨æˆ·æ´»åŠ¨ï¼ˆæ¯30-60ç§’ï¼‰
                    if activity_counter >= random.randint(30, 60):
                        await self.simulate_activity()
                        activity_counter = 0
                    
                    # å¿ƒè·³æ£€æµ‹
                    if not await self.check_connection():
                        logger.warning(f"[Scraper-{self.account_id}] è¿æ¥æ–­å¼€ï¼Œå°è¯•é‡è¿...")
                        await self.reconnect()
                        
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] å¯åŠ¨å¤±è´¥: {str(e)}")
            # æ›´æ–°è´¦å·çŠ¶æ€ä¸ºç¦»çº¿
            db.execute(
                "UPDATE accounts SET status = 'offline' WHERE id = ?",
                (self.account_id,)
            )
            db.commit()
            raise
        finally:
            await self.stop()
    
    async def simulate_human_behavior(self):
        """âœ… åæ£€æµ‹å¢å¼º: æ¨¡æ‹Ÿäººç±»è¡Œä¸ºï¼ˆé¼ æ ‡ç§»åŠ¨å’Œæ»šåŠ¨ï¼‰"""
        try:
            # éšæœºç§»åŠ¨é¼ æ ‡
            for _ in range(random.randint(2, 5)):
                await self.page.mouse.move(
                    random.randint(100, 1800),
                    random.randint(100, 1000),
                    steps=random.randint(10, 30)  # åˆ†æ­¥ç§»åŠ¨ï¼Œæ›´è‡ªç„¶
                )
                await asyncio.sleep(random.uniform(0.1, 0.3))
            
            # éšæœºæ»šåŠ¨
            for _ in range(random.randint(1, 3)):
                await self.page.evaluate(
                    f'window.scrollBy(0, {random.randint(-200, 200)})'
                )
                await asyncio.sleep(random.uniform(0.2, 0.5))
            
            logger.debug(f"[Scraper-{self.account_id}] å®Œæˆäººç±»è¡Œä¸ºæ¨¡æ‹Ÿ")
            
        except Exception as e:
            logger.debug(f"[Scraper-{self.account_id}] æ¨¡æ‹Ÿè¡Œä¸ºå¤±è´¥: {e}")
    
    async def simulate_activity(self):
        """âœ… åæ£€æµ‹å¢å¼º: å®šæœŸæ¨¡æ‹Ÿç”¨æˆ·æ´»åŠ¨"""
        try:
            actions = [
                # éšæœºé¼ æ ‡ç§»åŠ¨
                lambda: self.page.mouse.move(
                    random.randint(100, 1800),
                    random.randint(100, 1000)
                ),
                # éšæœºæ»šåŠ¨
                lambda: self.page.evaluate(
                    f'window.scrollBy(0, {random.randint(-100, 100)})'
                ),
                # éšæœºåœé¡¿
                lambda: asyncio.sleep(random.uniform(0.5, 2)),
            ]
            
            # éšæœºæ‰§è¡Œ1-2ä¸ªåŠ¨ä½œ
            for _ in range(random.randint(1, 2)):
                action = random.choice(actions)
                await action()
            
            logger.debug(f"[Scraper-{self.account_id}] æ‰§è¡Œæ´»åŠ¨æ¨¡æ‹Ÿ")
            
        except Exception as e:
            logger.debug(f"[Scraper-{self.account_id}] æ´»åŠ¨æ¨¡æ‹Ÿå¤±è´¥: {e}")
    
    async def check_login_status(self) -> bool:
        """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
        try:
            # ç­‰å¾…åº”ç”¨å®¹å™¨å‡ºç°
            await self.page.wait_for_selector('.app-container', timeout=5000)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•è¡¨å•
            login_form = await self.page.query_selector('form[class*="login"]')
            if login_form:
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·ä¿¡æ¯å…ƒç´ 
            user_info = await self.page.query_selector('[class*="user-info"]')
            if user_info:
                return True
            
            # å°è¯•æ‰§è¡ŒJSæ£€æŸ¥
            is_logged_in = await self.page.evaluate('''() => {
                return window.localStorage.getItem('token') !== null;
            }''')
            
            return is_logged_in
            
        except Exception as e:
            logger.debug(f"[Scraper-{self.account_id}] ç™»å½•çŠ¶æ€æ£€æŸ¥å¼‚å¸¸: {e}")
            return False
    
    async def login_with_password(self, email: str, password: str) -> bool:
        """è´¦å·å¯†ç ç™»å½•"""
        try:
            logger.info(f"[Scraper-{self.account_id}] å¼€å§‹è´¦å·å¯†ç ç™»å½•...")
            
            # ç­‰å¾…ç™»å½•è¡¨å•
            await self.page.wait_for_selector('input[name="email"], input[type="email"]', timeout=10000)
            
            # å¡«å†™é‚®ç®±
            await self.page.fill('input[name="email"], input[type="email"]', email)
            await asyncio.sleep(0.5)
            
            # å¡«å†™å¯†ç 
            await self.page.fill('input[name="password"], input[type="password"]', password)
            await asyncio.sleep(0.5)
            
            # ç‚¹å‡»ç™»å½•æŒ‰é’®
            await self.page.click('button[type="submit"]')
            
            # ç­‰å¾…ç™»å½•ç»“æœ
            try:
                # ç­‰å¾…åº”ç”¨å®¹å™¨å‡ºç°ï¼ˆç™»å½•æˆåŠŸï¼‰
                await self.page.wait_for_selector('.app-container', timeout=10000)
                logger.info(f"[Scraper-{self.account_id}] ç™»å½•æˆåŠŸ")
                
                # ä¿å­˜Cookie
                await self.save_cookies()
                
                return True
                
            except Exception:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦éªŒè¯ç 
                captcha_element = await self.page.query_selector('.captcha-container, [class*="captcha"]')
                if captcha_element:
                    logger.warning(f"[Scraper-{self.account_id}] éœ€è¦éªŒè¯ç ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥...")
                    success = await self.handle_captcha()
                    if success:
                        await self.save_cookies()
                    return success
                else:
                    # æ£€æŸ¥é”™è¯¯æç¤º
                    error_element = await self.page.query_selector('.error-message, [class*="error"]')
                    if error_element:
                        error_text = await error_element.text_content()
                        logger.error(f"[Scraper-{self.account_id}] ç™»å½•å¤±è´¥: {error_text}")
                    return False
                    
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] ç™»å½•å¼‚å¸¸: {str(e)}")
            return False
    
    async def handle_captcha(self) -> bool:
        """å¤„ç†éªŒè¯ç """
        try:
            # æˆªå–éªŒè¯ç å›¾ç‰‡
            captcha_element = await self.page.query_selector('.captcha-image, img[class*="captcha"]')
            if not captcha_element:
                logger.error(f"[Scraper-{self.account_id}] æœªæ‰¾åˆ°éªŒè¯ç å›¾ç‰‡å…ƒç´ ")
                return False
            
            # æˆªå›¾
            image_data = await captcha_element.screenshot()
            
            # ä¿å­˜éªŒè¯ç åˆ°æ•°æ®åº“
            captcha_id = self.save_captcha_to_db(image_data)
            
            logger.info(f"[Scraper-{self.account_id}] éªŒè¯ç ID: {captcha_id}ï¼Œç­‰å¾…ç”¨æˆ·è¾“å…¥...")
            
            # ç­‰å¾…ç”¨æˆ·è¾“å…¥éªŒè¯ç ï¼ˆæœ€å¤š60ç§’ï¼‰
            code = await self.wait_for_captcha_input(captcha_id, timeout=60)
            
            if not code:
                logger.error(f"[Scraper-{self.account_id}] éªŒè¯ç è¾“å…¥è¶…æ—¶")
                return False
            
            # å¡«å†™éªŒè¯ç 
            await self.page.fill('input[name="captcha"], input[class*="captcha"]', code)
            await asyncio.sleep(0.5)
            
            # å†æ¬¡ç‚¹å‡»ç™»å½•
            await self.page.click('button[type="submit"]')
            
            # ç­‰å¾…ç™»å½•ç»“æœ
            try:
                await self.page.wait_for_selector('.app-container', timeout=10000)
                logger.info(f"[Scraper-{self.account_id}] éªŒè¯ç éªŒè¯æˆåŠŸï¼Œç™»å½•å®Œæˆ")
                return True
            except Exception:
                logger.error(f"[Scraper-{self.account_id}] éªŒè¯ç é”™è¯¯æˆ–ç™»å½•å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] éªŒè¯ç å¤„ç†å¼‚å¸¸: {str(e)}")
            return False
    
    def save_captcha_to_db(self, image_data: bytes) -> int:
        """ä¿å­˜éªŒè¯ç åˆ°æ•°æ®åº“"""
        # åˆ›å»ºéªŒè¯ç è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        db.execute("""
            CREATE TABLE IF NOT EXISTS captcha_queue (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                account_id INTEGER NOT NULL,
                image_data BLOB NOT NULL,
                code TEXT,
                status TEXT DEFAULT 'pending',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # æ’å…¥éªŒè¯ç 
        cursor = db.execute(
            "INSERT INTO captcha_queue (account_id, image_data) VALUES (?, ?)",
            (self.account_id, image_data)
        )
        db.commit()
        
        return cursor.lastrowid
    
    async def wait_for_captcha_input(self, captcha_id: int, timeout: int = 60) -> Optional[str]:
        """ç­‰å¾…ç”¨æˆ·è¾“å…¥éªŒè¯ç """
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            # æŸ¥è¯¢éªŒè¯ç çŠ¶æ€
            result = db.execute(
                "SELECT code, status FROM captcha_queue WHERE id = ?",
                (captcha_id,)
            ).fetchone()
            
            if result and result['code']:
                # ç”¨æˆ·å·²è¾“å…¥
                return result['code']
            
            await asyncio.sleep(1)
        
        return None
    
    async def handle_websocket(self, ws):
        """å¤„ç†WebSocketè¿æ¥"""
        logger.info(f"[Scraper-{self.account_id}] WebSocketè¿æ¥å·²å»ºç«‹: {ws.url}")
        
        # ç›‘å¬æ¶ˆæ¯
        ws.on('framereceived', lambda payload: 
            asyncio.create_task(self.process_websocket_message(payload))
        )
        
        # ç›‘å¬å…³é—­
        ws.on('close', lambda: 
            logger.warning(f"[Scraper-{self.account_id}] WebSocketè¿æ¥å·²å…³é—­")
        )
    
    async def process_websocket_message(self, payload: bytes):
        """å¤„ç†WebSocketæ¶ˆæ¯"""
        try:
            # è§£ææ¶ˆæ¯
            data = json.loads(payload.decode('utf-8'))
            
            # åˆ¤æ–­æ¶ˆæ¯ç±»å‹
            msg_type = data.get('type')
            
            if msg_type == 'MESSAGE_CREATE':
                # æ–°æ¶ˆæ¯
                message = await self.parse_message(data)
                
                if message:
                    # è®°å½•æ—¥å¿—
                    logger.info(
                        f"[Scraper-{self.account_id}] æ”¶åˆ°æ¶ˆæ¯: "
                        f"é¢‘é“={message.get('channel_name', 'Unknown')}, "
                        f"ä½œè€…={message['author']['username']}, "
                        f"å†…å®¹={message['content'][:30]}..."
                    )
                    
                    # å…¥é˜Ÿå¤„ç†
                    await redis_queue.enqueue('message_queue', message)
                    
                    # è°ƒç”¨æ¶ˆæ¯å¤„ç†å™¨
                    for handler in self.message_handlers:
                        try:
                            await handler(message)
                        except Exception as e:
                            logger.error(f"æ¶ˆæ¯å¤„ç†å™¨æ‰§è¡Œå¤±è´¥: {e}")
            
            elif msg_type == 'MESSAGE_UPDATE':
                # æ¶ˆæ¯æ›´æ–°
                logger.debug(f"[Scraper-{self.account_id}] æ¶ˆæ¯æ›´æ–°: {data.get('d', {}).get('msg_id')}")
            
            elif msg_type == 'MESSAGE_DELETE':
                # æ¶ˆæ¯åˆ é™¤
                logger.debug(f"[Scraper-{self.account_id}] æ¶ˆæ¯åˆ é™¤: {data.get('d', {}).get('msg_id')}")
            
            elif msg_type == 'ADDED_REACTION' or msg_type == 'DELETED_REACTION':
                # è¡¨æƒ…ååº”
                logger.debug(f"[Scraper-{self.account_id}] è¡¨æƒ…ååº”: {msg_type}")
            
        except json.JSONDecodeError:
            logger.debug(f"[Scraper-{self.account_id}] WebSocketæ¶ˆæ¯ä¸æ˜¯JSONæ ¼å¼")
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] å¤„ç†WebSocketæ¶ˆæ¯å¼‚å¸¸: {str(e)}")
    
    async def parse_message(self, data: Dict) -> Optional[Dict]:
        """è§£ææ¶ˆæ¯æ•°æ®"""
        try:
            d = data.get('d', {})
            
            # åŸºç¡€ä¿¡æ¯
            message = {
                'account_id': self.account_id,
                'kook_message_id': d.get('msg_id'),
                'channel_id': d.get('target_id'),
                'server_id': d.get('guild_id'),
                'message_type': d.get('type', 1),  # 1=æ–‡æœ¬, 2=å›¾ç‰‡, etc.
                'content': d.get('content', ''),
                'created_at': d.get('msg_timestamp', int(time.time() * 1000)),
            }
            
            # ä½œè€…ä¿¡æ¯
            author = d.get('author', {})
            message['author'] = {
                'id': author.get('id'),
                'username': author.get('username'),
                'nickname': author.get('nickname'),
                'avatar': author.get('avatar'),
                'bot': author.get('bot', False)
            }
            
            # é™„ä»¶
            attachments = d.get('attachments', [])
            if attachments:
                message['attachments'] = attachments
            
            # @æåŠ
            message['mention_all'] = d.get('mention_all', False)
            message['mention_users'] = d.get('mention', [])
            message['mention_roles'] = d.get('mention_roles', [])
            
            # å¼•ç”¨æ¶ˆæ¯
            if 'quote' in d and d['quote']:
                message['quote'] = {
                    'id': d['quote'].get('id'),
                    'content': d['quote'].get('content'),
                    'author': d['quote'].get('author', {})
                }
            
            # å°è¯•è·å–é¢‘é“å’ŒæœåŠ¡å™¨åç§°
            try:
                channel_info = await self.get_channel_info(d.get('target_id'))
                if channel_info:
                    message['channel_name'] = channel_info.get('name')
                    message['server_name'] = channel_info.get('server_name')
            except Exception as e:
                logger.debug(f"è·å–é¢‘é“ä¿¡æ¯å¤±è´¥: {e}")
                pass
            
            return message
            
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] æ¶ˆæ¯è§£æå¤±è´¥: {str(e)}")
            return None
    
    async def get_channel_info(self, channel_id: str) -> Optional[Dict]:
        """
        è·å–é¢‘é“ä¿¡æ¯ï¼ˆä»é¡µé¢JSæ‰§è¡Œï¼‰
        
        é€šè¿‡æ‰§è¡Œé¡µé¢JSè·å–KOOKçš„é¢‘é“å’ŒæœåŠ¡å™¨ä¿¡æ¯
        """
        if not self.page or self.page.is_closed():
            return None
        
        try:
            # å°è¯•ä»é¡µé¢çš„å…¨å±€å¯¹è±¡è·å–é¢‘é“ä¿¡æ¯
            channel_data = await self.page.evaluate('''(channelId) => {
                // å°è¯•ä»windowå¯¹è±¡è·å–KOOKçš„æ•°æ®
                // KOOKå¯èƒ½åœ¨window.__INITIAL_STATE__æˆ–å…¶ä»–å…¨å±€å˜é‡å­˜å‚¨æ•°æ®
                
                // æ–¹æ³•1: å°è¯•ä»DOMå…ƒç´ è·å–
                const channelElement = document.querySelector(`[data-channel-id="${channelId}"]`);
                if (channelElement) {
                    return {
                        name: channelElement.getAttribute('data-channel-name') || 
                              channelElement.textContent?.trim(),
                        server_name: channelElement.getAttribute('data-server-name'),
                        server_id: channelElement.getAttribute('data-server-id')
                    };
                }
                
                // æ–¹æ³•2: å°è¯•ä»å…¨å±€çŠ¶æ€è·å–ï¼ˆå¦‚æœKOOKä½¿ç”¨Reduxæˆ–Vuexï¼‰
                if (window.__KOOK_STORE__) {
                    const channel = window.__KOOK_STORE__.channels?.find(c => c.id === channelId);
                    if (channel) {
                        return {
                            name: channel.name,
                            server_name: channel.guild?.name,
                            server_id: channel.guild_id
                        };
                    }
                }
                
                // æ–¹æ³•3: å°è¯•ä»localStorageè·å–ç¼“å­˜çš„é¢‘é“æ•°æ®
                try {
                    const cachedData = localStorage.getItem('kook_channels');
                    if (cachedData) {
                        const channels = JSON.parse(cachedData);
                        const channel = channels.find(c => c.id === channelId);
                        if (channel) {
                            return {
                                name: channel.name,
                                server_name: channel.server_name,
                                server_id: channel.server_id
                            };
                        }
                    }
                } catch (e) {
                    console.error('Failed to parse cached channel data:', e);
                }
                
                return null;
            }''', channel_id)
            
            if channel_data:
                logger.debug(f"ä»é¡µé¢è·å–é¢‘é“ä¿¡æ¯æˆåŠŸ: {channel_data}")
                
                # ç¼“å­˜åˆ°å†…å­˜ï¼ˆå¯é€‰ï¼šä¹Ÿå¯ä»¥å­˜åˆ°æ•°æ®åº“ï¼‰
                if not hasattr(self, '_channel_cache'):
                    self._channel_cache = {}
                self._channel_cache[channel_id] = channel_data
                
                return channel_data
            else:
                logger.warning(f"æ— æ³•ä»é¡µé¢è·å–é¢‘é“ {channel_id} çš„ä¿¡æ¯")
                
                # å°è¯•ä»æ•°æ®åº“çš„æ˜ å°„è¡¨è·å–
                mapping = db.execute(
                    "SELECT * FROM channel_mappings WHERE kook_channel_id = ? LIMIT 1",
                    (channel_id,)
                ).fetchone()
                
                if mapping:
                    return {
                        'name': mapping['kook_channel_name'],
                        'server_id': mapping['kook_server_id'],
                        'server_name': mapping.get('kook_server_name', 'æœªçŸ¥æœåŠ¡å™¨')
                    }
                
                return None
            
        except Exception as e:
            logger.error(f"è·å–é¢‘é“ä¿¡æ¯å¼‚å¸¸: {e}")
            
            # é™çº§æ–¹æ¡ˆï¼šå°è¯•ä»æ•°æ®åº“è·å–
            try:
                mapping = db.execute(
                    "SELECT * FROM channel_mappings WHERE kook_channel_id = ? LIMIT 1",
                    (channel_id,)
                ).fetchone()
                
                if mapping:
                    return {
                        'name': mapping['kook_channel_name'],
                        'server_id': mapping['kook_server_id'],
                        'server_name': mapping.get('kook_server_name', 'æœªçŸ¥æœåŠ¡å™¨')
                    }
            except Exception:
                pass
            
            return None
    
    async def check_connection(self) -> bool:
        """æ£€æŸ¥è¿æ¥çŠ¶æ€"""
        if not self.page or self.page.is_closed():
            return False
        
        try:
            # æ‰§è¡Œç®€å•çš„JSæ£€æŸ¥é¡µé¢æ˜¯å¦æ´»è·ƒ
            await self.page.evaluate('() => true')
            return True
        except Exception:
            return False
    
    async def reconnect(self):
        """é‡æ–°è¿æ¥"""
        if self.reconnect_count >= self.max_reconnect:
            logger.error(f"[Scraper-{self.account_id}] è¶…è¿‡æœ€å¤§é‡è¿æ¬¡æ•°ï¼Œåœæ­¢æŠ“å–")
            self.is_running = False
            return
        
        self.reconnect_count += 1
        logger.info(f"[Scraper-{self.account_id}] ç¬¬{self.reconnect_count}æ¬¡é‡è¿...")
        
        try:
            # é‡æ–°åŠ è½½é¡µé¢
            await self.page.reload(wait_until='networkidle')
            await asyncio.sleep(2)
            
            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            if not await self.check_login_status():
                logger.warning(f"[Scraper-{self.account_id}] é‡è¿åæœªç™»å½•")
                return
            
            logger.info(f"[Scraper-{self.account_id}] é‡è¿æˆåŠŸ")
            self.reconnect_count = 0
            
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] é‡è¿å¤±è´¥: {str(e)}")
            await asyncio.sleep(30)  # ç­‰å¾…30ç§’åé‡è¯•
    
    def load_cookies(self) -> List[Dict]:
        """ä»æ•°æ®åº“åŠ è½½Cookie"""
        try:
            result = db.execute(
                "SELECT cookie FROM accounts WHERE id = ?",
                (self.account_id,)
            ).fetchone()
            
            if result and result['cookie']:
                cookies = json.loads(result['cookie'])
                
                # ğŸ”§ ä¿®å¤sameSiteå­—æ®µï¼ˆé˜²æ­¢ChromiumæŠ¥é”™ï¼‰
                for cookie in cookies:
                    if cookie.get("sameSite") in ["no_restriction", "unspecified"]:
                        cookie["sameSite"] = "None"
                    # ç¡®ä¿secureæ ‡å¿—
                    if cookie.get("sameSite") == "None":
                        cookie["secure"] = True
                
                return cookies
            
            return []
            
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] åŠ è½½Cookieå¤±è´¥: {str(e)}")
            return []
    
    async def save_cookies(self):
        """ä¿å­˜Cookieåˆ°æ•°æ®åº“"""
        try:
            cookies = await self.context.cookies()
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            db.execute(
                "UPDATE accounts SET cookie = ? WHERE id = ?",
                (json.dumps(cookies), self.account_id)
            )
            db.commit()
            
            logger.info(f"[Scraper-{self.account_id}] Cookieå·²ä¿å­˜")
            
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] ä¿å­˜Cookieå¤±è´¥: {str(e)}")
    
    def decrypt_password(self, encrypted: str) -> str:
        """è§£å¯†å¯†ç """
        from ..utils.crypto import crypto_manager
        return crypto_manager.decrypt(encrypted)
    
    def register_message_handler(self, handler: Callable):
        """æ³¨å†Œæ¶ˆæ¯å¤„ç†å™¨"""
        self.message_handlers.append(handler)
    
    def _run_sync_playwright(self):
        """åŒæ­¥ç‰ˆæœ¬çš„Playwrightè¿è¡Œï¼ˆWindowså…¼å®¹æ¨¡å¼ï¼‰"""
        try:
            with sync_playwright() as p:
                # å¯åŠ¨æµè§ˆå™¨
                browser = p.chromium.launch(
                    headless=False,
                    args=[
                        '--no-sandbox',
                        '--disable-setuid-sandbox',
                        '--disable-dev-shm-usage',
                        '--disable-blink-features=AutomationControlled',
                        '--disable-automation',
                        '--disable-infobars',
                        '--no-first-run',
                        '--no-default-browser-check',
                    ]
                )
                
                logger.info(f"[Scraper-{self.account_id}] æµè§ˆå™¨å·²å¯åŠ¨")
                
                # è·å–è´¦å·ä¿¡æ¯ - ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“æŸ¥è¯¢
                with db.get_connection() as conn:
                    cursor = conn.execute(
                        "SELECT cookie FROM accounts WHERE id = ?",
                        (self.account_id,)
                    )
                    row = cursor.fetchone()
                
                if not row:
                    logger.error(f"[Scraper-{self.account_id}] è´¦å·ä¸å­˜åœ¨")
                    browser.close()
                    return
                
                # å¤„ç†Cookie - å…¼å®¹dictå’Œtupleä¸¤ç§è¿”å›ç±»å‹
                cookie_str = row['cookie'] if isinstance(row, dict) else row[0]
                
                if not cookie_str or cookie_str.strip() == '':
                    logger.error(f"[Scraper-{self.account_id}] Cookieä¸ºç©º")
                    browser.close()
                    return
                
                # è§£æCookie JSON
                try:
                    cookie_data = json.loads(cookie_str)
                    logger.info(f"[Scraper-{self.account_id}] Cookieè§£ææˆåŠŸï¼Œå…±{len(cookie_data)}ä¸ª")
                except json.JSONDecodeError as e:
                    logger.error(f"[Scraper-{self.account_id}] Cookie JSONè§£æå¤±è´¥: {e}")
                    browser.close()
                    return
                
                # ğŸ”§ ä¿®å¤sameSiteå­—æ®µï¼ˆé˜²æ­¢ChromiumæŠ¥é”™ï¼‰
                for cookie in cookie_data:
                    if cookie.get("sameSite") in ["no_restriction", "unspecified"]:
                        cookie["sameSite"] = "None"
                    # ç¡®ä¿secureæ ‡å¿—
                    if cookie.get("sameSite") == "None":
                        cookie["secure"] = True
                logger.info(f"[Scraper-{self.account_id}] Cookieå·²ä¿®å¤sameSiteå­—æ®µ")
                
                # åˆ›å»ºä¸Šä¸‹æ–‡å¹¶æ·»åŠ Cookie
                context = browser.new_context()
                context.add_cookies(cookie_data)
                logger.info(f"[Scraper-{self.account_id}] Cookieå·²åŠ è½½")
                
                # æ‰“å¼€é¡µé¢
                page = context.new_page()
                logger.info(f"[Scraper-{self.account_id}] æ­£åœ¨è®¿é—®KOOK...")
                page.goto("https://www.kookapp.cn/app/", wait_until="networkidle")
                
                logger.info(f"[Scraper-{self.account_id}] âœ… æµè§ˆå™¨å·²å¯åŠ¨å¹¶è®¿é—®KOOKï¼ˆåŒæ­¥æ¨¡å¼ï¼‰")
                
                # ä¿æŒè¿è¡Œï¼Œç›‘å¬WebSocketæ¶ˆæ¯
                self.is_running = True
                while self.is_running:
                    import time
                    time.sleep(1)
                
                # æ¸…ç†
                page.close()
                context.close()
                browser.close()
                
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] åŒæ­¥æ¨¡å¼å¯åŠ¨å¤±è´¥: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
    
    async def stop(self):
        """åœæ­¢æŠ“å–å™¨"""
        logger.info(f"[Scraper-{self.account_id}] æ­£åœ¨åœæ­¢...")
        
        self.is_running = False
        
        try:
            if self.page and not self.page.is_closed():
                await self.page.close()
            
            if self.context:
                await self.context.close()
            
            if self.browser:
                await self.browser.close()
            
            # æ›´æ–°è´¦å·çŠ¶æ€
            db.execute(
                "UPDATE accounts SET status = 'offline' WHERE id = ?",
                (self.account_id,)
            )
            db.commit()
            
            logger.info(f"[Scraper-{self.account_id}] å·²åœæ­¢")
            
        except Exception as e:
            logger.error(f"[Scraper-{self.account_id}] åœæ­¢å¼‚å¸¸: {str(e)}")


class ScraperManager:
    """âœ… P2-10ä¼˜åŒ–: æŠ“å–å™¨ç®¡ç†å™¨ï¼ˆæ”¯æŒå¹¶è¡Œé™åˆ¶ï¼‰"""
    
    def __init__(self):
        self.scrapers: Dict[int, KookScraper] = {}
        self.tasks: Dict[int, asyncio.Task] = {}
        # âœ… P2-10ä¼˜åŒ–: å¯¼å…¥è´¦å·é™åˆ¶å™¨
        from ..utils.account_limiter import account_limiter
        self.limiter = account_limiter
    
    async def start_scraper(self, account_id: int):
        """
        âœ… P2-10ä¼˜åŒ–: å¯åŠ¨æŒ‡å®šè´¦å·çš„æŠ“å–å™¨ï¼ˆå¸¦å¹¶å‘é™åˆ¶ï¼‰
        
        å¦‚æœè¶…è¿‡æœ€å¤§å¹¶è¡Œæ•°ï¼Œä¼šç­‰å¾…å…¶ä»–è´¦å·é‡Šæ”¾èµ„æº
        """
        if account_id in self.scrapers:
            logger.warning(f"è´¦å·{account_id}çš„æŠ“å–å™¨å·²åœ¨è¿è¡Œ")
            return
        
        # âœ… P2-10ä¼˜åŒ–: è·å–æ‰§è¡Œè®¸å¯
        acquired = await self.limiter.acquire(account_id)
        
        if not acquired:
            logger.warning(f"è´¦å·{account_id}æœªèƒ½è·å–æ‰§è¡Œè®¸å¯")
            return
        
        try:
            scraper = KookScraper(account_id)
            self.scrapers[account_id] = scraper
            
            # åˆ›å»ºä»»åŠ¡
            task = asyncio.create_task(self._run_scraper_with_cleanup(account_id, scraper))
            self.tasks[account_id] = task
            
            logger.info(f"è´¦å·{account_id}çš„æŠ“å–å™¨å·²å¯åŠ¨")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨è´¦å·{account_id}çš„æŠ“å–å™¨å¤±è´¥: {e}")
            # é‡Šæ”¾è®¸å¯
            self.limiter.release(account_id)
            raise
    
    async def _run_scraper_with_cleanup(self, account_id: int, scraper: KookScraper):
        """
        è¿è¡ŒæŠ“å–å™¨å¹¶ç¡®ä¿æ¸…ç†èµ„æº
        
        Args:
            account_id: è´¦å·ID
            scraper: æŠ“å–å™¨å®ä¾‹
        """
        try:
            await scraper.start()
        finally:
            # ç¡®ä¿é‡Šæ”¾é™åˆ¶å™¨è®¸å¯
            self.limiter.release(account_id)
    
    async def stop_scraper(self, account_id: int):
        """åœæ­¢æŒ‡å®šè´¦å·çš„æŠ“å–å™¨"""
        if account_id not in self.scrapers:
            logger.warning(f"è´¦å·{account_id}çš„æŠ“å–å™¨æœªè¿è¡Œ")
            return
        
        scraper = self.scrapers[account_id]
        await scraper.stop()
        
        # å–æ¶ˆä»»åŠ¡
        if account_id in self.tasks:
            self.tasks[account_id].cancel()
            try:
                await self.tasks[account_id]
            except asyncio.CancelledError:
                pass
            del self.tasks[account_id]
        
        del self.scrapers[account_id]
        
        logger.info(f"è´¦å·{account_id}çš„æŠ“å–å™¨å·²åœæ­¢")
    
    async def start_all(self):
        """å¯åŠ¨æ‰€æœ‰åœ¨çº¿è´¦å·çš„æŠ“å–å™¨"""
        accounts = db.execute(
            "SELECT id FROM accounts WHERE status = 'online' OR status IS NULL"
        ).fetchall()
        
        for account in accounts:
            try:
                await self.start_scraper(account['id'])
            except Exception as e:
                logger.error(f"å¯åŠ¨è´¦å·{account['id']}çš„æŠ“å–å™¨å¤±è´¥: {e}")
    
    async def stop_all(self):
        """åœæ­¢æ‰€æœ‰æŠ“å–å™¨"""
        account_ids = list(self.scrapers.keys())
        
        for account_id in account_ids:
            try:
                await self.stop_scraper(account_id)
            except Exception as e:
                logger.error(f"åœæ­¢è´¦å·{account_id}çš„æŠ“å–å™¨å¤±è´¥: {e}")
    
    def get_scraper(self, account_id: int) -> Optional[KookScraper]:
        """è·å–æŒ‡å®šè´¦å·çš„æŠ“å–å™¨"""
        return self.scrapers.get(account_id)
    
    def get_all_scrapers(self) -> Dict[int, KookScraper]:
        """è·å–æ‰€æœ‰æŠ“å–å™¨"""
        return self.scrapers


# å…¨å±€æŠ“å–å™¨ç®¡ç†å™¨
scraper_manager = ScraperManager()
