"""
å…¨å±€å†…å­˜ç›‘æ§æ¨¡å—
å®æ—¶ç›‘æ§å†…å­˜ä½¿ç”¨ï¼Œé˜²æ­¢å†…å­˜æ³„æ¼
"""
import asyncio
import psutil
from typing import Dict, Any, Optional
from datetime import datetime
from collections import OrderedDict
from .logger import logger


class LRUCache:
    """
    çº¿ç¨‹å®‰å…¨çš„LRUç¼“å­˜ï¼ˆå…¨å±€å¤ç”¨ï¼‰
    é˜²æ­¢ç¼“å­˜æ— é™å¢é•¿å¯¼è‡´å†…å­˜æ³„æ¼
    """
    
    def __init__(self, max_size: int = 10000, name: str = "unnamed"):
        """
        åˆå§‹åŒ–LRUç¼“å­˜
        
        Args:
            max_size: æœ€å¤§ç¼“å­˜å¤§å°
            name: ç¼“å­˜åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        """
        self.cache = OrderedDict()
        self.max_size = max_size
        self.name = name
        self.hits = 0
        self.misses = 0
    
    def add(self, key: str, value: Any = True):
        """
        æ·»åŠ é”®å€¼å¯¹åˆ°ç¼“å­˜
        
        Args:
            key: é”®
            value: å€¼ï¼ˆé»˜è®¤Trueï¼‰
        """
        if key in self.cache:
            # å·²å­˜åœ¨ï¼Œç§»åˆ°æœ«å°¾ï¼ˆæœ€è¿‘ä½¿ç”¨ï¼‰
            self.cache.move_to_end(key)
            self.hits += 1
        else:
            # æ–°å¢
            self.cache[key] = value
            self.misses += 1
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé™åˆ¶
            if len(self.cache) > self.max_size:
                # åˆ é™¤æœ€æ—§çš„é¡¹ï¼ˆæœ€å‰é¢çš„ï¼‰
                removed_key, _ = self.cache.popitem(last=False)
                logger.debug(f"LRUç¼“å­˜[{self.name}]å·²æ»¡ï¼Œç§»é™¤æœ€æ—§é¡¹: {removed_key}")
    
    def get(self, key: str, default: Any = None) -> Any:
        """
        è·å–ç¼“å­˜å€¼
        
        Args:
            key: é”®
            default: é»˜è®¤å€¼
            
        Returns:
            ç¼“å­˜å€¼æˆ–é»˜è®¤å€¼
        """
        if key in self.cache:
            self.cache.move_to_end(key)
            self.hits += 1
            return self.cache[key]
        else:
            self.misses += 1
            return default
    
    def __contains__(self, key: str) -> bool:
        """æ£€æŸ¥é”®æ˜¯å¦å­˜åœ¨"""
        exists = key in self.cache
        if exists:
            self.hits += 1
        else:
            self.misses += 1
        return exists
    
    def __len__(self) -> int:
        """è·å–ç¼“å­˜å¤§å°"""
        return len(self.cache)
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        size = len(self.cache)
        self.cache.clear()
        self.hits = 0
        self.misses = 0
        logger.info(f"LRUç¼“å­˜[{self.name}]å·²æ¸…ç©ºï¼Œé‡Šæ”¾ {size} ä¸ªé¡¹")
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total_requests = self.hits + self.misses
        hit_rate = self.hits / total_requests if total_requests > 0 else 0
        
        return {
            'name': self.name,
            'size': len(self.cache),
            'max_size': self.max_size,
            'hits': self.hits,
            'misses': self.misses,
            'hit_rate': f"{hit_rate * 100:.2f}%",
            'usage_percent': f"{len(self.cache) / self.max_size * 100:.1f}%"
        }


class MemoryMonitor:
    """
    å…¨å±€å†…å­˜ç›‘æ§å™¨
    å®šæœŸæ£€æŸ¥å†…å­˜ä½¿ç”¨ï¼Œè¶…é™æ—¶è‡ªåŠ¨æ¸…ç†
    """
    
    def __init__(self, max_memory_mb: int = 500, check_interval: int = 60):
        """
        åˆå§‹åŒ–å†…å­˜ç›‘æ§å™¨
        
        Args:
            max_memory_mb: æœ€å¤§å†…å­˜é™åˆ¶ï¼ˆMBï¼‰
            check_interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        """
        self.max_memory_mb = max_memory_mb
        self.check_interval = check_interval
        self.process = psutil.Process()
        self.is_running = False
        self._monitor_task: Optional[asyncio.Task] = None
        
        # æ³¨å†Œçš„LRUç¼“å­˜
        self.registered_caches: Dict[str, LRUCache] = {}
        
        # å†…å­˜å†å²è®°å½•ï¼ˆæœ€è¿‘100æ¬¡ï¼‰
        self.memory_history = OrderedDict()
        self.max_history = 100
        
        # æ¸…ç†å›è°ƒ
        self.cleanup_callbacks = []
        
        logger.info(f"âœ… å†…å­˜ç›‘æ§å™¨å·²åˆå§‹åŒ–ï¼šæœ€å¤§{max_memory_mb}MBï¼Œæ£€æŸ¥é—´éš”{check_interval}ç§’")
    
    def register_cache(self, name: str, cache: LRUCache):
        """
        æ³¨å†ŒLRUç¼“å­˜åˆ°ç›‘æ§å™¨
        
        Args:
            name: ç¼“å­˜åç§°
            cache: LRUç¼“å­˜å®ä¾‹
        """
        self.registered_caches[name] = cache
        logger.info(f"âœ… LRUç¼“å­˜å·²æ³¨å†Œ: {name} (max_size={cache.max_size})")
    
    def register_cleanup_callback(self, callback):
        """
        æ³¨å†Œæ¸…ç†å›è°ƒå‡½æ•°
        
        Args:
            callback: å¼‚æ­¥æ¸…ç†å‡½æ•°
        """
        self.cleanup_callbacks.append(callback)
    
    async def start(self):
        """å¯åŠ¨å†…å­˜ç›‘æ§"""
        if self.is_running:
            logger.warning("å†…å­˜ç›‘æ§å™¨å·²åœ¨è¿è¡Œ")
            return
        
        self.is_running = True
        self._monitor_task = asyncio.create_task(self._monitor_loop())
        logger.info("ğŸ” å†…å­˜ç›‘æ§å™¨å·²å¯åŠ¨")
    
    async def stop(self):
        """åœæ­¢å†…å­˜ç›‘æ§"""
        self.is_running = False
        if self._monitor_task:
            self._monitor_task.cancel()
            try:
                await self._monitor_task
            except asyncio.CancelledError:
                pass
        logger.info("å†…å­˜ç›‘æ§å™¨å·²åœæ­¢")
    
    async def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_running:
            try:
                await self.check_and_cleanup()
                await asyncio.sleep(self.check_interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"å†…å­˜ç›‘æ§å¼‚å¸¸: {str(e)}")
                await asyncio.sleep(self.check_interval)
    
    async def check_and_cleanup(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨ï¼Œè¶…é™æ—¶æ¸…ç†"""
        try:
            # è·å–å†…å­˜ä¿¡æ¯
            memory_info = self.process.memory_info()
            memory_mb = memory_info.rss / (1024 * 1024)
            memory_percent = self.process.memory_percent()
            
            # è®°å½•å†å²
            timestamp = datetime.now().isoformat()
            self.memory_history[timestamp] = {
                'memory_mb': memory_mb,
                'memory_percent': memory_percent
            }
            
            # é™åˆ¶å†å²è®°å½•æ•°é‡
            if len(self.memory_history) > self.max_history:
                self.memory_history.popitem(last=False)
            
            # æ£€æŸ¥æ˜¯å¦è¶…é™
            if memory_mb > self.max_memory_mb:
                logger.warning(
                    f"âš ï¸ å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory_mb:.2f}MB / {self.max_memory_mb}MB "
                    f"({memory_percent:.1f}%)ï¼Œå¼€å§‹æ¸…ç†..."
                )
                await self.cleanup_all()
            else:
                # å®šæœŸæŠ¥å‘Šï¼ˆæ¯10æ¬¡æ£€æŸ¥ï¼‰
                if len(self.memory_history) % 10 == 0:
                    logger.info(
                        f"ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_mb:.2f}MB / {self.max_memory_mb}MB "
                        f"({memory_percent:.1f}%)"
                    )
            
        except Exception as e:
            logger.error(f"å†…å­˜æ£€æŸ¥å¤±è´¥: {str(e)}")
    
    async def cleanup_all(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜å’Œèµ„æº"""
        logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†å†…å­˜...")
        
        cleaned_items = 0
        
        # 1. æ¸…ç†æ³¨å†Œçš„LRUç¼“å­˜
        for name, cache in self.registered_caches.items():
            size_before = len(cache)
            # æ¸…ç†ä¸€åŠæœ€æ—§çš„é¡¹
            items_to_remove = size_before // 2
            for _ in range(items_to_remove):
                if len(cache.cache) > 0:
                    cache.cache.popitem(last=False)
                    cleaned_items += 1
            
            logger.info(
                f"  æ¸…ç†ç¼“å­˜[{name}]: {size_before} -> {len(cache)} "
                f"(-{items_to_remove}é¡¹)"
            )
        
        # 2. è°ƒç”¨è‡ªå®šä¹‰æ¸…ç†å›è°ƒ
        for callback in self.cleanup_callbacks:
            try:
                await callback()
            except Exception as e:
                logger.error(f"æ¸…ç†å›è°ƒå¤±è´¥: {str(e)}")
        
        # 3. å¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        # 4. æ£€æŸ¥æ¸…ç†æ•ˆæœ
        memory_after = self.process.memory_info().rss / (1024 * 1024)
        logger.info(
            f"âœ… æ¸…ç†å®Œæˆï¼šé‡Šæ”¾äº† {cleaned_items} ä¸ªç¼“å­˜é¡¹ï¼Œ"
            f"å†…å­˜: {memory_after:.2f}MB"
        )
    
    def get_memory_stats(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ç»Ÿè®¡ä¿¡æ¯"""
        memory_info = self.process.memory_info()
        memory_mb = memory_info.rss / (1024 * 1024)
        memory_percent = self.process.memory_percent()
        
        # è·å–æ‰€æœ‰ç¼“å­˜ç»Ÿè®¡
        cache_stats = {}
        total_cache_size = 0
        for name, cache in self.registered_caches.items():
            cache_stats[name] = cache.get_stats()
            total_cache_size += len(cache)
        
        # è®¡ç®—å†å²è¶‹åŠ¿
        if len(self.memory_history) > 1:
            recent_memories = list(self.memory_history.values())
            first_memory = recent_memories[0]['memory_mb']
            last_memory = recent_memories[-1]['memory_mb']
            trend = last_memory - first_memory
            trend_text = f"+{trend:.2f}MB" if trend > 0 else f"{trend:.2f}MB"
        else:
            trend_text = "N/A"
        
        return {
            'current_memory_mb': round(memory_mb, 2),
            'max_memory_mb': self.max_memory_mb,
            'memory_percent': round(memory_percent, 2),
            'usage_ratio': f"{memory_mb / self.max_memory_mb * 100:.1f}%",
            'total_cache_items': total_cache_size,
            'registered_caches': len(self.registered_caches),
            'cache_details': cache_stats,
            'trend': trend_text,
            'history_count': len(self.memory_history)
        }
    
    def get_recommendations(self) -> list:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        memory_mb = self.process.memory_info().rss / (1024 * 1024)
        usage_ratio = memory_mb / self.max_memory_mb
        
        if usage_ratio > 0.9:
            recommendations.append("å†…å­˜ä½¿ç”¨è¶…è¿‡90%ï¼Œå»ºè®®é‡å¯åº”ç”¨")
        elif usage_ratio > 0.7:
            recommendations.append("å†…å­˜ä½¿ç”¨è¾ƒé«˜ï¼Œå»ºè®®å‡å°‘å¹¶å‘ä»»åŠ¡")
        
        # æ£€æŸ¥ç¼“å­˜ä½¿ç”¨ç‡
        for name, cache in self.registered_caches.items():
            cache_usage = len(cache) / cache.max_size
            if cache_usage > 0.9:
                recommendations.append(f"ç¼“å­˜[{name}]æ¥è¿‘æ»¡è½½ï¼Œå»ºè®®å¢åŠ max_size")
            
            stats = cache.get_stats()
            hit_rate = float(stats['hit_rate'].rstrip('%'))
            if hit_rate < 50:
                recommendations.append(f"ç¼“å­˜[{name}]å‘½ä¸­ç‡ä½({stats['hit_rate']})ï¼Œå»ºè®®ä¼˜åŒ–")
        
        if not recommendations:
            recommendations.append("å†…å­˜ä½¿ç”¨æ­£å¸¸ï¼Œæ— éœ€ä¼˜åŒ–")
        
        return recommendations


# åˆ›å»ºå…¨å±€å†…å­˜ç›‘æ§å™¨å®ä¾‹
memory_monitor = MemoryMonitor(max_memory_mb=500, check_interval=60)


# å·¥å‚å‡½æ•°ï¼šåˆ›å»ºæ³¨å†Œçš„LRUç¼“å­˜
def create_lru_cache(name: str, max_size: int = 10000) -> LRUCache:
    """
    åˆ›å»ºå¹¶æ³¨å†ŒLRUç¼“å­˜
    
    Args:
        name: ç¼“å­˜åç§°
        max_size: æœ€å¤§å¤§å°
        
    Returns:
        LRUç¼“å­˜å®ä¾‹
    """
    cache = LRUCache(max_size=max_size, name=name)
    memory_monitor.register_cache(name, cache)
    return cache
