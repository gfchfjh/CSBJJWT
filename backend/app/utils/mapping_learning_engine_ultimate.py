"""
ğŸ§  P1-2ä¼˜åŒ–: AIæ˜ å°„å­¦ä¹ å¼•æ“ï¼ˆç»ˆæç‰ˆï¼‰

åŠŸèƒ½ï¼š
1. ä¸‰é‡åŒ¹é…ç®—æ³•ï¼ˆå®Œå…¨+ç›¸ä¼¼+å…³é”®è¯ï¼‰
2. ä¸­è‹±æ–‡ç¿»è¯‘è¡¨ï¼ˆ10+å¸¸ç”¨è¯ï¼‰
3. å†å²é¢‘ç‡å­¦ä¹ ï¼ˆå¸¦æ—¶é—´è¡°å‡ï¼‰
4. æŒç»­ä¼˜åŒ–æ¨èå‡†ç¡®åº¦

ä½œè€…: KOOK Forwarder Team
ç‰ˆæœ¬: 11.0.0
æ—¥æœŸ: 2025-10-28
"""
import difflib
import re
import time
import math
from typing import List, Dict, Optional, Tuple
from collections import defaultdict
from ..utils.logger import logger
from ..database import db


class MappingLearningEngine:
    """AIæ˜ å°„å­¦ä¹ å¼•æ“ï¼ˆv2.0å¢å¼ºç‰ˆï¼‰"""
    
    def __init__(self):
        # ä¸­è‹±æ–‡ç¿»è¯‘è¡¨
        self.translation_table = {
            'å…¬å‘Š': ['announcement', 'announce', 'notice', 'news'],
            'æ´»åŠ¨': ['event', 'activity', 'campaign'],
            'æ›´æ–°': ['update', 'changelog', 'release', 'patch'],
            'æŠ€æœ¯': ['tech', 'technical', 'dev', 'development'],
            'è®¨è®º': ['discuss', 'discussion', 'talk', 'chat'],
            'å¸®åŠ©': ['help', 'support', 'faq', 'question'],
            'åé¦ˆ': ['feedback', 'suggestion', 'report'],
            'é—²èŠ': ['general', 'off-topic', 'chat', 'random'],
            'è§„åˆ™': ['rule', 'guideline', 'policy'],
            'èµ„æº': ['resource', 'link', 'material'],
            'æ•™ç¨‹': ['tutorial', 'guide', 'howto'],
            'æµ‹è¯•': ['test', 'testing', 'beta'],
            'å¼€å‘': ['dev', 'development', 'coding'],
            'è®¾è®¡': ['design', 'art', 'creative'],
            'éŸ³ä¹': ['music', 'audio', 'sound'],
        }
        
        # åå‘ç¿»è¯‘è¡¨ï¼ˆè‹±æ–‡â†’ä¸­æ–‡ï¼‰
        self.reverse_translation = {}
        for cn, en_list in self.translation_table.items():
            for en in en_list:
                self.reverse_translation[en] = cn
        
        # æ˜ å°„å†å²è®°å½• {(kook_channel_id, target_channel_id): count}
        self.mapping_history = defaultdict(int)
        
        # æ˜ å°„æ—¶é—´æˆ³ {(kook_channel_id, target_channel_id): timestamp}
        self.mapping_timestamps = {}
        
        # ä»æ•°æ®åº“åŠ è½½å†å²
        self.load_history()
        
        logger.info(f"âœ… AIæ˜ å°„å­¦ä¹ å¼•æ“å·²åˆå§‹åŒ–ï¼ˆç¿»è¯‘è¡¨:{len(self.translation_table)}è¯ï¼‰")
    
    def load_history(self):
        """ä»æ•°æ®åº“åŠ è½½å†å²æ˜ å°„è®°å½•"""
        try:
            history = db.get_mapping_learning_history()
            
            for record in history:
                key = (record['kook_channel_id'], record['target_channel_id'])
                self.mapping_history[key] = record['use_count']
                self.mapping_timestamps[key] = record['last_used_timestamp']
            
            if history:
                logger.info(f"âœ… å·²åŠ è½½{len(history)}æ¡æ˜ å°„å†å²è®°å½•")
        except Exception as e:
            logger.warning(f"âš ï¸  åŠ è½½æ˜ å°„å†å²å¤±è´¥: {str(e)}")
    
    def recommend_mappings(
        self, 
        kook_channel: Dict, 
        target_channels: List[Dict]
    ) -> List[Tuple[Dict, float, str]]:
        """
        æ¨èæ˜ å°„ï¼ˆä¸‰é‡ç®—æ³• + å†å²é¢‘ç‡ï¼‰
        
        Args:
            kook_channel: KOOKé¢‘é“ä¿¡æ¯ {'id', 'name', 'type'}
            target_channels: ç›®æ ‡é¢‘é“åˆ—è¡¨ [{'id', 'name', 'platform'}, ...]
            
        Returns:
            æ¨èåˆ—è¡¨ [(target_channel, confidence, reason), ...]
            æŒ‰ç½®ä¿¡åº¦é™åºæ’åˆ—
        """
        kook_name = kook_channel['name'].lower()
        kook_id = kook_channel['id']
        
        recommendations = []
        
        logger.debug(f"ğŸ” ä¸ºKOOKé¢‘é“'{kook_channel['name']}'æ¨èæ˜ å°„...")
        
        for target in target_channels:
            target_name = target['name'].lower()
            target_id = target['id']
            
            # 1. å®Œå…¨åŒ¹é…ï¼ˆ40%æƒé‡ï¼‰
            exact_match = self._exact_match_score(kook_name, target_name)
            
            # 2. ç›¸ä¼¼åŒ¹é…ï¼ˆ30%æƒé‡ï¼‰
            similarity = self._similarity_score(kook_name, target_name)
            
            # 3. å…³é”®è¯åŒ¹é…ï¼ˆ20%æƒé‡ï¼‰
            keyword_match = self._keyword_match_score(kook_name, target_name)
            
            # 4. å†å²é¢‘ç‡ï¼ˆ10%æƒé‡ï¼‰
            history_score = self._history_score(kook_id, target_id)
            
            # ç»¼åˆç½®ä¿¡åº¦
            confidence = (
                exact_match * 0.4 +
                similarity * 0.3 +
                keyword_match * 0.2 +
                history_score * 0.1
            )
            
            # ç”Ÿæˆæ¨èåŸå› 
            reason = self._generate_reason(
                exact_match, similarity, keyword_match, history_score
            )
            
            recommendations.append((target, confidence, reason))
            
            logger.debug(
                f"  {target['platform']} - {target['name']}: "
                f"ç½®ä¿¡åº¦={confidence:.2f} ({reason})"
            )
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        recommendations.sort(key=lambda x: x[1], reverse=True)
        
        logger.info(
            f"âœ… ç”Ÿæˆ{len(recommendations)}ä¸ªæ¨èï¼Œ"
            f"æœ€é«˜ç½®ä¿¡åº¦={recommendations[0][1]:.2f if recommendations else 0}"
        )
        
        return recommendations
    
    def _exact_match_score(self, name1: str, name2: str) -> float:
        """
        å®Œå…¨åŒ¹é…è¯„åˆ†ï¼ˆè€ƒè™‘ç¿»è¯‘ï¼‰
        
        Returns:
            1.0 = å®Œå…¨åŒ¹é…
            0.8 = ç¿»è¯‘åŒ¹é…
            0.0 = ä¸åŒ¹é…
        """
        # å»é™¤ç‰¹æ®Šå­—ç¬¦
        clean1 = re.sub(r'[#\-_\s]+', '', name1)
        clean2 = re.sub(r'[#\-_\s]+', '', name2)
        
        # ç›´æ¥åŒ¹é…
        if clean1 == clean2:
            return 1.0
        
        # æ£€æŸ¥ç¿»è¯‘åŒ¹é… - ä¸­æ–‡ â†’ è‹±æ–‡
        for cn_word, en_words in self.translation_table.items():
            if cn_word in name1:
                for en_word in en_words:
                    if en_word in name2:
                        return 0.8
        
        # æ£€æŸ¥ç¿»è¯‘åŒ¹é… - è‹±æ–‡ â†’ ä¸­æ–‡
        for en_word, cn_word in self.reverse_translation.items():
            if en_word in name1 and cn_word in name2:
                return 0.8
        
        return 0.0
    
    def _similarity_score(self, name1: str, name2: str) -> float:
        """
        ç›¸ä¼¼åº¦è¯„åˆ†ï¼ˆç¼–è¾‘è·ç¦»ï¼‰
        
        ä½¿ç”¨SequenceMatcherè®¡ç®—å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
        
        Returns:
            0.0 - 1.0
        """
        # å»é™¤ç‰¹æ®Šå­—ç¬¦
        clean1 = re.sub(r'[#\-_\s]+', '', name1)
        clean2 = re.sub(r'[#\-_\s]+', '', name2)
        
        # ä½¿ç”¨difflibè®¡ç®—ç›¸ä¼¼åº¦
        similarity = difflib.SequenceMatcher(None, clean1, clean2).ratio()
        
        return similarity
    
    def _keyword_match_score(self, name1: str, name2: str) -> float:
        """
        å…³é”®è¯åŒ¹é…è¯„åˆ†
        
        æå–å…³é”®è¯ï¼Œè®¡ç®—åŒ¹é…æ¯”ä¾‹
        
        Returns:
            0.0 - 1.0
        """
        # æå–ä¸­æ–‡å…³é”®è¯
        cn_keywords1 = re.findall(r'[\u4e00-\u9fa5]+', name1)
        cn_keywords2 = re.findall(r'[\u4e00-\u9fa5]+', name2)
        
        # æå–è‹±æ–‡å…³é”®è¯
        en_keywords1 = re.findall(r'[a-z]+', name1)
        en_keywords2 = re.findall(r'[a-z]+', name2)
        
        # åˆå¹¶
        keywords1 = set(cn_keywords1 + en_keywords1)
        keywords2 = set(cn_keywords2 + en_keywords2)
        
        if not keywords1 or not keywords2:
            return 0.0
        
        # è®¡ç®—äº¤é›†å æ¯”ï¼ˆJaccardç›¸ä¼¼åº¦ï¼‰
        intersection = keywords1 & keywords2
        union = keywords1 | keywords2
        
        jaccard = len(intersection) / len(union) if union else 0.0
        
        # è€ƒè™‘ç¿»è¯‘åŒ¹é…
        translated_matches = 0
        for kw1 in keywords1:
            # æ£€æŸ¥ä¸­æ–‡â†’è‹±æ–‡ç¿»è¯‘
            if kw1 in self.translation_table:
                en_words = self.translation_table[kw1]
                if any(en in keywords2 for en in en_words):
                    translated_matches += 1
            
            # æ£€æŸ¥è‹±æ–‡â†’ä¸­æ–‡ç¿»è¯‘
            if kw1 in self.reverse_translation:
                cn_word = self.reverse_translation[kw1]
                if cn_word in keywords2:
                    translated_matches += 1
        
        # ç¿»è¯‘åŒ¹é…åŠ åˆ†ï¼ˆæ¯ä¸ªåŒ¹é…+0.2ï¼Œæœ€å¤š+0.5ï¼‰
        translation_bonus = min(0.5, translated_matches * 0.2)
        
        return min(1.0, jaccard + translation_bonus)
    
    def _history_score(self, kook_channel_id: str, target_channel_id: str) -> float:
        """
        å†å²é¢‘ç‡è¯„åˆ†ï¼ˆå¸¦æ—¶é—´è¡°å‡ï¼‰
        
        å…¬å¼: score = (use_count / max_count) * time_decay
        
        æ—¶é—´è¡°å‡: decay = e^(-Î»t)ï¼Œå…¶ä¸­tä¸ºå¤©æ•°ï¼ŒÎ»=0.01
        
        Returns:
            0.0 - 1.0
        """
        key = (kook_channel_id, target_channel_id)
        
        use_count = self.mapping_history.get(key, 0)
        
        if use_count == 0:
            return 0.0
        
        # æ‰¾åˆ°æœ€å¤§ä½¿ç”¨æ¬¡æ•°ï¼ˆå½’ä¸€åŒ–ï¼‰
        max_count = max(self.mapping_history.values()) if self.mapping_history else 1
        
        normalized_count = use_count / max_count
        
        # æ—¶é—´è¡°å‡
        if key in self.mapping_timestamps:
            last_used = self.mapping_timestamps[key]
            days_ago = (time.time() - last_used) / 86400
            
            # æŒ‡æ•°è¡°å‡: e^(-0.01 * days)
            # 100å¤©åè¡°å‡åˆ°37%ï¼Œ200å¤©åè¡°å‡åˆ°14%
            time_decay = math.exp(-0.01 * days_ago)
        else:
            time_decay = 1.0
        
        return normalized_count * time_decay
    
    def _generate_reason(
        self, 
        exact: float, 
        similarity: float, 
        keyword: float, 
        history: float
    ) -> str:
        """ç”Ÿæˆæ¨èåŸå› """
        reasons = []
        
        if exact >= 0.8:
            reasons.append("å®Œå…¨åŒ¹é…" if exact == 1.0 else "ç¿»è¯‘åŒ¹é…")
        
        if similarity >= 0.7:
            reasons.append(f"åç§°ç›¸ä¼¼åº¦{similarity*100:.0f}%")
        
        if keyword >= 0.5:
            reasons.append("å…³é”®è¯åŒ¹é…")
        
        if history >= 0.5:
            reasons.append("å†å²è®°å½•")
        
        if not reasons:
            # æ‰¾å‡ºæœ€é«˜çš„åˆ†æ•°
            scores = {
                'åç§°ç›¸ä¼¼': similarity,
                'å…³é”®è¯': keyword,
                'å†å²': history
            }
            best = max(scores.items(), key=lambda x: x[1])
            reasons.append(f"{best[0]}({best[1]*100:.0f}%)")
        
        return " | ".join(reasons)
    
    def record_mapping(
        self, 
        kook_channel_id: str, 
        target_channel_id: str
    ):
        """è®°å½•ç”¨æˆ·çš„æ˜ å°„é€‰æ‹©ï¼ˆç”¨äºå­¦ä¹ ï¼‰"""
        key = (kook_channel_id, target_channel_id)
        
        # å¢åŠ ä½¿ç”¨æ¬¡æ•°
        self.mapping_history[key] += 1
        
        # æ›´æ–°æ—¶é—´æˆ³
        self.mapping_timestamps[key] = time.time()
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        try:
            db.save_mapping_learning_record(
                kook_channel_id=kook_channel_id,
                target_channel_id=target_channel_id,
                use_count=self.mapping_history[key],
                last_used_timestamp=self.mapping_timestamps[key]
            )
            
            logger.debug(f"âœ… å·²è®°å½•æ˜ å°„å­¦ä¹ : {kook_channel_id} -> {target_channel_id}")
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ˜ å°„å­¦ä¹ è®°å½•å¤±è´¥: {str(e)}")
    
    def get_stats(self) -> Dict:
        """è·å–å­¦ä¹ å¼•æ“ç»Ÿè®¡ä¿¡æ¯"""
        if not self.mapping_history:
            most_used = None
        else:
            most_used_key = max(self.mapping_history.items(), key=lambda x: x[1])
            most_used = {
                'kook_channel_id': most_used_key[0][0],
                'target_channel_id': most_used_key[0][1],
                'use_count': most_used_key[1]
            }
        
        return {
            'total_mappings_learned': len(self.mapping_history),
            'total_uses': sum(self.mapping_history.values()),
            'most_used_mapping': most_used,
            'translation_table_size': len(self.translation_table),
            'reverse_translation_size': len(self.reverse_translation)
        }
    
    def export_translation_table(self) -> Dict:
        """å¯¼å‡ºç¿»è¯‘è¡¨ï¼ˆä¾›ç”¨æˆ·è‡ªå®šä¹‰ï¼‰"""
        return self.translation_table.copy()
    
    def import_translation_table(self, table: Dict):
        """å¯¼å…¥è‡ªå®šä¹‰ç¿»è¯‘è¡¨"""
        self.translation_table.update(table)
        
        # æ›´æ–°åå‘è¡¨
        for cn, en_list in table.items():
            for en in en_list:
                self.reverse_translation[en] = cn
        
        logger.info(f"âœ… å·²å¯¼å…¥è‡ªå®šä¹‰ç¿»è¯‘è¡¨ï¼Œå½“å‰å…±{len(self.translation_table)}è¯")


# åˆ›å»ºå…¨å±€å®ä¾‹
mapping_learning_engine = MappingLearningEngine()
