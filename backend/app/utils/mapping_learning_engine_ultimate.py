"""
æ˜ å°„å­¦ä¹ å¼•æ“
âœ… P1-2æ·±åº¦ä¼˜åŒ–: æœºå™¨å­¦ä¹  + ä¸‰é‡åŒ¹é…ç®—æ³•
"""
import time
from typing import List, Dict, Tuple
from difflib import SequenceMatcher
from ..database import db
from ..utils.logger import logger


class MappingLearningEngine:
    """æ˜ å°„å­¦ä¹ å¼•æ“ï¼ˆæ™ºèƒ½æ¨èï¼‰"""
    
    def __init__(self):
        self.learning_data = {}  # {(kook_channel, target): {"count": int, "last_used": timestamp}}
        self.load_learning_data()
    
    def load_learning_data(self):
        """ä»æ•°æ®åº“åŠ è½½å­¦ä¹ æ•°æ®"""
        try:
            # æŸ¥è¯¢æ‰€æœ‰æ˜ å°„å†å²
            history = db.get_mapping_history() if hasattr(db, 'get_mapping_history') else []
            
            for record in history:
                key = (record['kook_channel_id'], record['target_channel_id'])
                if key not in self.learning_data:
                    self.learning_data[key] = {"count": 0, "last_used": 0}
                
                self.learning_data[key]["count"] += 1
                self.learning_data[key]["last_used"] = record.get('timestamp', time.time())
            
            logger.info(f"âœ… åŠ è½½äº† {len(self.learning_data)} æ¡æ˜ å°„å­¦ä¹ æ•°æ®")
        except Exception as e:
            logger.warning(f"âš ï¸ åŠ è½½æ˜ å°„å­¦ä¹ æ•°æ®å¤±è´¥: {e}")
    
    def suggest_mapping(self, kook_channel_name: str, 
                       target_channels: List[Dict]) -> List[Tuple[Dict, float]]:
        """
        æ™ºèƒ½æ¨èæ˜ å°„ï¼ˆä¸‰é‡åŒ¹é…ç®—æ³•ï¼‰
        
        Args:
            kook_channel_name: KOOKé¢‘é“åç§°
            target_channels: ç›®æ ‡å¹³å°é¢‘é“åˆ—è¡¨
        
        Returns:
            [(é¢‘é“, ç½®ä¿¡åº¦), ...] æŒ‰ç½®ä¿¡åº¦é™åºæ’åˆ—
        """
        results = []
        
        for target in target_channels:
            target_name = target.get('name', '')
            target_id = target.get('id', '')
            
            # ğŸ”¥ ä¸‰é‡åŒ¹é…ç®—æ³•
            scores = {
                'exact_match': self._exact_match(kook_channel_name, target_name),
                'similar_match': self._similar_match(kook_channel_name, target_name),
                'keyword_match': self._keyword_match(kook_channel_name, target_name),
                'frequency_score': self._frequency_score(target_id)
            }
            
            # åŠ æƒè®¡ç®—ç»¼åˆç½®ä¿¡åº¦
            confidence = (
                scores['exact_match'] * 0.4 +
                scores['similar_match'] * 0.3 +
                scores['keyword_match'] * 0.2 +
                scores['frequency_score'] * 0.1
            )
            
            if confidence > 0.3:  # é˜ˆå€¼ï¼š30%
                results.append((target, confidence))
        
        # æŒ‰ç½®ä¿¡åº¦é™åºæ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        
        return results
    
    def _exact_match(self, kook_name: str, target_name: str) -> float:
        """å®Œå…¨åŒ¹é…ï¼ˆ100%ç½®ä¿¡åº¦ï¼‰"""
        kook_clean = self._clean_channel_name(kook_name)
        target_clean = self._clean_channel_name(target_name)
        
        if kook_clean.lower() == target_clean.lower():
            return 1.0
        
        # ä¸­è‹±æ–‡æ˜ å°„è¡¨
        translations = {
            'å…¬å‘Š': ['announcements', 'announce', 'notice', 'news'],
            'æ´»åŠ¨': ['events', 'activity', 'activities'],
            'æ›´æ–°': ['updates', 'update', 'changelog'],
            'æ—¥å¿—': ['log', 'logs', 'changelog'],
            'è®¨è®º': ['discussion', 'discuss', 'talk'],
            'æŠ€æœ¯': ['tech', 'technical', 'dev'],
            'é€šçŸ¥': ['notification', 'notice'],
            'èŠå¤©': ['chat', 'talk'],
            'æ¸¸æˆ': ['game', 'gaming'],
            'å¨±ä¹': ['entertainment', 'fun']
        }
        
        for cn, en_list in translations.items():
            if cn in kook_clean:
                if any(en in target_clean.lower() for en in en_list):
                    return 0.9
        
        return 0.0
    
    def _similar_match(self, kook_name: str, target_name: str) -> float:
        """ç›¸ä¼¼åŒ¹é…ï¼ˆåŸºäºç¼–è¾‘è·ç¦»ï¼‰"""
        kook_clean = self._clean_channel_name(kook_name)
        target_clean = self._clean_channel_name(target_name)
        
        similarity = SequenceMatcher(None, kook_clean.lower(), target_clean.lower()).ratio()
        
        return similarity
    
    def _keyword_match(self, kook_name: str, target_name: str) -> float:
        """å…³é”®è¯åŒ¹é…"""
        keyword_groups = {
            'å…¬å‘Š': ['announce', 'announcement', 'notice', 'news', 'å…¬å‘Š', 'é€šçŸ¥'],
            'æ´»åŠ¨': ['event', 'activity', 'æ´»åŠ¨', 'æ¯”èµ›'],
            'æ›´æ–°': ['update', 'changelog', 'release', 'æ›´æ–°', 'ç‰ˆæœ¬'],
            'è®¨è®º': ['discussion', 'talk', 'chat', 'è®¨è®º', 'èŠå¤©'],
            'æŠ€æœ¯': ['tech', 'technical', 'dev', 'æŠ€æœ¯', 'å¼€å‘'],
            'æ¸¸æˆ': ['game', 'gaming', 'play', 'æ¸¸æˆ'],
            'å¸®åŠ©': ['help', 'support', 'faq', 'å¸®åŠ©', 'æ”¯æŒ']
        }
        
        kook_clean = self._clean_channel_name(kook_name).lower()
        target_clean = self._clean_channel_name(target_name).lower()
        
        for group_name, keywords in keyword_groups.items():
            kook_has = any(kw in kook_clean for kw in keywords)
            target_has = any(kw in target_clean for kw in keywords)
            
            if kook_has and target_has:
                return 0.8
        
        return 0.0
    
    def _frequency_score(self, target_channel_id: str) -> float:
        """å†å²é¢‘ç‡æ‰“åˆ†"""
        total_count = sum(
            data["count"] for key, data in self.learning_data.items()
            if key[1] == target_channel_id
        )
        
        return min(total_count / 100, 1.0)
    
    def _clean_channel_name(self, name: str) -> str:
        """æ¸…ç†é¢‘é“åç§°"""
        import re
        name = name.lstrip('#@*-_ ')
        name = re.sub(r'[^\w\s\u4e00-\u9fff]', '', name)
        return name.strip()
    
    def record_mapping(self, kook_channel_id: str, target_channel_id: str):
        """è®°å½•æ˜ å°„è¡Œä¸ºï¼ˆç”¨äºå­¦ä¹ ï¼‰"""
        key = (kook_channel_id, target_channel_id)
        
        if key not in self.learning_data:
            self.learning_data[key] = {"count": 0, "last_used": 0}
        
        self.learning_data[key]["count"] += 1
        self.learning_data[key]["last_used"] = time.time()
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        try:
            if hasattr(db, 'save_mapping_history'):
                db.save_mapping_history({
                    'kook_channel_id': kook_channel_id,
                    'target_channel_id': target_channel_id,
                    'timestamp': time.time()
                })
        except Exception as e:
            logger.warning(f"ä¿å­˜æ˜ å°„å†å²å¤±è´¥: {e}")
        
        logger.debug(f"ğŸ“ è®°å½•æ˜ å°„å­¦ä¹ : {kook_channel_id} â†’ {target_channel_id}")
    
    def get_stats(self) -> Dict:
        """è·å–å­¦ä¹ ç»Ÿè®¡ä¿¡æ¯"""
        total_mappings = len(self.learning_data)
        total_count = sum(data["count"] for data in self.learning_data.values())
        
        top_mappings = sorted(
            self.learning_data.items(),
            key=lambda x: x[1]["count"],
            reverse=True
        )[:10]
        
        return {
            'total_unique_mappings': total_mappings,
            'total_mapping_count': total_count,
            'top_mappings': [
                {
                    'kook_channel': k[0],
                    'target_channel': k[1],
                    'count': v["count"],
                    'last_used': time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(v["last_used"]))
                }
                for k, v in top_mappings
            ]
        }


# åˆ›å»ºå…¨å±€å®ä¾‹
mapping_learning_engine = MappingLearningEngine()
