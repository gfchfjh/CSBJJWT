"""
æ•°æ®åº“ä¼˜åŒ–å·¥å…·
åŠŸèƒ½ï¼š
1. æ·»åŠ å¤åˆç´¢å¼•
2. æŸ¥è¯¢æ€§èƒ½åˆ†æ
3. æ•°æ®å½’æ¡£
4. æ•°æ®åº“ç»´æŠ¤
"""
import sqlite3
from typing import List, Dict
from pathlib import Path
from datetime import datetime, timedelta
from ..config import DB_PATH
from ..utils.logger import logger


class DatabaseOptimizer:
    """æ•°æ®åº“ä¼˜åŒ–å™¨"""
    
    def __init__(self, db_path: Path = DB_PATH):
        self.db_path = db_path
    
    def create_optimized_indexes(self):
        """
        åˆ›å»ºä¼˜åŒ–çš„ç´¢å¼•
        
        å¤åˆç´¢å¼•å¯ä»¥æ˜¾è‘—æå‡è”åˆæŸ¥è¯¢æ€§èƒ½
        """
        logger.info("å¼€å§‹åˆ›å»ºä¼˜åŒ–ç´¢å¼•...")
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # å·²å­˜åœ¨çš„ç´¢å¼•ä¼šè‡ªåŠ¨è·³è¿‡ï¼ˆIF NOT EXISTSï¼‰
            indexes = [
                # message_logsè¡¨å¤åˆç´¢å¼•
                """CREATE INDEX IF NOT EXISTS idx_logs_status_time 
                   ON message_logs(status, created_at DESC)""",
                
                """CREATE INDEX IF NOT EXISTS idx_logs_channel_status 
                   ON message_logs(kook_channel_id, status, created_at DESC)""",
                
                """CREATE INDEX IF NOT EXISTS idx_logs_platform_status 
                   ON message_logs(target_platform, status, created_at DESC)""",
                
                # channel_mappingsè¡¨å¤åˆç´¢å¼•
                """CREATE INDEX IF NOT EXISTS idx_mapping_channel_enabled 
                   ON channel_mappings(kook_channel_id, enabled)""",
                
                """CREATE INDEX IF NOT EXISTS idx_mapping_platform_bot 
                   ON channel_mappings(target_platform, target_bot_id)""",
                
                # accountsè¡¨ç´¢å¼•
                """CREATE INDEX IF NOT EXISTS idx_accounts_status 
                   ON accounts(status, last_active DESC)""",
                
                # bot_configsè¡¨ç´¢å¼•
                """CREATE INDEX IF NOT EXISTS idx_bots_platform_status 
                   ON bot_configs(platform, status)""",
            ]
            
            for idx_sql in indexes:
                try:
                    cursor.execute(idx_sql)
                    idx_name = idx_sql.split()[5]  # æå–ç´¢å¼•å
                    logger.info(f"  âœ… åˆ›å»ºç´¢å¼•: {idx_name}")
                except Exception as e:
                    logger.error(f"  âŒ åˆ›å»ºç´¢å¼•å¤±è´¥: {str(e)}")
            
            conn.commit()
        
        logger.info("âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ")
    
    def analyze_query_performance(self, query: str) -> Dict:
        """
        åˆ†ææŸ¥è¯¢æ€§èƒ½
        
        ä½¿ç”¨EXPLAIN QUERY PLANæŸ¥çœ‹æ‰§è¡Œè®¡åˆ’
        
        Args:
            query: SQLæŸ¥è¯¢è¯­å¥
            
        Returns:
            {
                'query': '...',
                'execution_plan': [...],
                'has_index': True/False,
                'suggestions': [...]
            }
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # è·å–æ‰§è¡Œè®¡åˆ’
            cursor.execute(f"EXPLAIN QUERY PLAN {query}")
            plan = cursor.fetchall()
            
            # åˆ†æè®¡åˆ’
            has_index = any('INDEX' in str(row) for row in plan)
            
            suggestions = []
            if not has_index:
                suggestions.append("å»ºè®®æ·»åŠ ç´¢å¼•ä»¥æå‡æŸ¥è¯¢æ€§èƒ½")
            
            return {
                'query': query,
                'execution_plan': [str(row) for row in plan],
                'has_index': has_index,
                'suggestions': suggestions
            }
    
    def archive_old_logs(self, days: int = 30) -> int:
        """
        å½’æ¡£æ—§æ—¥å¿—æ•°æ®
        
        å°†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ—¥å¿—ç§»åŠ¨åˆ°å½’æ¡£è¡¨
        
        Args:
            days: ä¿ç•™å¤©æ•°
            
        Returns:
            å½’æ¡£çš„è®°å½•æ•°
        """
        logger.info(f"å¼€å§‹å½’æ¡£ {days} å¤©å‰çš„æ—¥å¿—...")
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # åˆ›å»ºå½’æ¡£è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS message_logs_archive (
                    id INTEGER PRIMARY KEY,
                    kook_message_id TEXT NOT NULL,
                    kook_channel_id TEXT NOT NULL,
                    content TEXT,
                    message_type TEXT,
                    sender_name TEXT,
                    target_platform TEXT,
                    target_channel TEXT,
                    status TEXT,
                    error_message TEXT,
                    latency_ms INTEGER,
                    created_at TIMESTAMP,
                    archived_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # è®¡ç®—æˆªæ­¢æ—¥æœŸ
            cutoff_date = datetime.now() - timedelta(days=days)
            cutoff_str = cutoff_date.strftime('%Y-%m-%d %H:%M:%S')
            
            # ç§»åŠ¨æ•°æ®åˆ°å½’æ¡£è¡¨
            cursor.execute("""
                INSERT INTO message_logs_archive 
                SELECT *, NULL FROM message_logs 
                WHERE created_at < ?
            """, (cutoff_str,))
            
            archived_count = cursor.rowcount
            
            # ä»ä¸»è¡¨åˆ é™¤
            cursor.execute("DELETE FROM message_logs WHERE created_at < ?", (cutoff_str,))
            
            conn.commit()
        
        logger.info(f"âœ… å·²å½’æ¡£ {archived_count} æ¡æ—¥å¿—è®°å½•")
        return archived_count
    
    def vacuum_database(self):
        """
        å‹ç¼©æ•°æ®åº“
        
        å›æ”¶å·²åˆ é™¤æ•°æ®å ç”¨çš„ç©ºé—´
        """
        logger.info("å¼€å§‹å‹ç¼©æ•°æ®åº“...")
        
        with sqlite3.connect(self.db_path) as conn:
            # è·å–å‹ç¼©å‰å¤§å°
            before_size = Path(self.db_path).stat().st_size / (1024 * 1024)
            
            conn.execute("VACUUM")
            
            # è·å–å‹ç¼©åå¤§å°
            after_size = Path(self.db_path).stat().st_size / (1024 * 1024)
            saved = before_size - after_size
        
        logger.info(f"âœ… æ•°æ®åº“å‹ç¼©å®Œæˆï¼ŒèŠ‚çœ {saved:.2f}MB ç©ºé—´")
    
    def get_database_stats(self) -> Dict:
        """
        è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            {
                'file_size_mb': 12.5,
                'table_counts': {...},
                'index_count': 15,
                'tables': [...]
            }
        """
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # æ•°æ®åº“æ–‡ä»¶å¤§å°
            file_size = Path(self.db_path).stat().st_size / (1024 * 1024)
            
            # è·å–æ‰€æœ‰è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            # ç»Ÿè®¡æ¯ä¸ªè¡¨çš„è®°å½•æ•°
            table_counts = {}
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                table_counts[table] = cursor.fetchone()[0]
            
            # ç´¢å¼•æ•°é‡
            cursor.execute("SELECT COUNT(*) FROM sqlite_master WHERE type='index'")
            index_count = cursor.fetchone()[0]
            
            return {
                'file_size_mb': round(file_size, 2),
                'table_counts': table_counts,
                'index_count': index_count,
                'tables': tables
            }
    
    def optimize_database(self, full: bool = False):
        """
        å…¨é¢ä¼˜åŒ–æ•°æ®åº“
        
        Args:
            full: æ˜¯å¦æ‰§è¡Œå®Œæ•´ä¼˜åŒ–ï¼ˆåŒ…æ‹¬å½’æ¡£å’Œå‹ç¼©ï¼‰
        """
        logger.info("ğŸ”§ å¼€å§‹æ•°æ®åº“ä¼˜åŒ–...")
        
        # 1. åˆ›å»ºç´¢å¼•
        self.create_optimized_indexes()
        
        # 2. åˆ†æç»Ÿè®¡ä¿¡æ¯ï¼ˆSQLiteè‡ªåŠ¨ï¼‰
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("ANALYZE")
        logger.info("âœ… å·²æ›´æ–°ç»Ÿè®¡ä¿¡æ¯")
        
        if full:
            # 3. å½’æ¡£æ—§æ•°æ®
            self.archive_old_logs(days=30)
            
            # 4. å‹ç¼©æ•°æ®åº“
            self.vacuum_database()
        
        # 5. æ˜¾ç¤ºä¼˜åŒ–åçš„ç»Ÿè®¡
        stats = self.get_database_stats()
        logger.info(f"âœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
        logger.info(f"   æ–‡ä»¶å¤§å°: {stats['file_size_mb']}MB")
        logger.info(f"   ç´¢å¼•æ•°é‡: {stats['index_count']}")
        logger.info(f"   è¡¨è®°å½•æ•°: {stats['table_counts']}")


# åˆ›å»ºå…¨å±€å®ä¾‹
db_optimizer = DatabaseOptimizer()
