"""
æ•°æ®åº“ä¼˜åŒ–å·¥å…·
âœ… P2-1æ·±åº¦ä¼˜åŒ–: è‡ªåŠ¨å½’æ¡£ + VACUUMå‹ç¼©
"""
import sqlite3
from pathlib import Path
from datetime import datetime, timedelta
from ..config import settings
from ..utils.logger import logger


class DatabaseOptimizer:
    """æ•°æ®åº“ä¼˜åŒ–å·¥å…·"""
    
    def __init__(self):
        self.db_path = str(settings.data_dir / "config.db")
    
    def archive_old_logs(self, days: int = 30) -> int:
        """
        å½’æ¡£æ—§æ—¥å¿—ï¼ˆç§»åŠ¨åˆ°å½’æ¡£è¡¨ï¼‰
        
        Args:
            days: å½’æ¡£å¤©æ•°é˜ˆå€¼
        
        Returns:
            å½’æ¡£çš„è®°å½•æ•°
        """
        try:
            cutoff_date = (datetime.now() - timedelta(days=days)).timestamp()
            
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºå½’æ¡£è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS message_logs_archive (
                    id INTEGER PRIMARY KEY,
                    kook_message_id TEXT,
                    kook_channel_id TEXT,
                    content TEXT,
                    message_type TEXT,
                    sender_name TEXT,
                    target_platform TEXT,
                    target_channel TEXT,
                    status TEXT,
                    error_message TEXT,
                    latency_ms INTEGER,
                    created_at TIMESTAMP,
                    archived_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # ç§»åŠ¨æ—§è®°å½•åˆ°å½’æ¡£è¡¨
            cursor.execute('''
                INSERT INTO message_logs_archive
                SELECT *, CURRENT_TIMESTAMP FROM message_logs
                WHERE created_at < ?
            ''', (cutoff_date,))
            
            archived_count = cursor.rowcount
            
            # åˆ é™¤ä¸»è¡¨ä¸­çš„æ—§è®°å½•
            cursor.execute('DELETE FROM message_logs WHERE created_at < ?', (cutoff_date,))
            
            conn.commit()
            conn.close()
            
            logger.info(f"ğŸ“¦ å½’æ¡£äº† {archived_count} æ¡æ—§æ—¥å¿—ï¼ˆ{days}å¤©å‰ï¼‰")
            
            return archived_count
        
        except Exception as e:
            logger.error(f"âŒ å½’æ¡£æ—¥å¿—å¤±è´¥: {e}")
            return 0
    
    def vacuum_database(self) -> dict:
        """
        æ‰§è¡ŒVACUUMå‹ç¼©æ•°æ®åº“
        
        Returns:
            å‹ç¼©ç»“æœ {"before": bytes, "after": bytes, "saved_percent": float}
        """
        try:
            db_path = Path(self.db_path)
            
            # è·å–å‹ç¼©å‰å¤§å°
            size_before = db_path.stat().st_size
            
            # æ‰§è¡ŒVACUUM
            conn = sqlite3.connect(str(db_path))
            conn.execute('VACUUM')
            conn.close()
            
            # è·å–å‹ç¼©åå¤§å°
            size_after = db_path.stat().st_size
            
            saved_percent = ((size_before - size_after) / size_before) * 100 if size_before > 0 else 0
            
            logger.info(f"ğŸ—œï¸ æ•°æ®åº“å‹ç¼©å®Œæˆ: {self._format_size(size_before)} â†’ {self._format_size(size_after)} (èŠ‚çœ {saved_percent:.1f}%)")
            
            return {
                "before": size_before,
                "after": size_after,
                "saved": size_before - size_after,
                "saved_percent": round(saved_percent, 2)
            }
        
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“å‹ç¼©å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def analyze_database(self) -> dict:
        """
        åˆ†ææ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            stats = {}
            
            for table in tables:
                # è·å–è®°å½•æ•°
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                
                stats[table] = {
                    "record_count": count
                }
            
            # æ•°æ®åº“æ–‡ä»¶å¤§å°
            db_size = Path(self.db_path).stat().st_size
            
            conn.close()
            
            return {
                "db_size": db_size,
                "db_size_formatted": self._format_size(db_size),
                "tables": stats
            }
        
        except Exception as e:
            logger.error(f"âŒ åˆ†ææ•°æ®åº“å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def _format_size(self, bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        for unit in ['B', 'KB', 'MB', 'GB']:
            if bytes < 1024:
                return f"{bytes:.2f} {unit}"
            bytes /= 1024
        return f"{bytes:.2f} TB"
    
    def optimize_all(self) -> dict:
        """
        æ‰§è¡Œå®Œæ•´ä¼˜åŒ–æµç¨‹
        
        Returns:
            ä¼˜åŒ–ç»“æœ
        """
        logger.info("ğŸ”§ å¼€å§‹æ•°æ®åº“å®Œæ•´ä¼˜åŒ–...")
        
        results = {}
        
        # 1. å½’æ¡£æ—§æ—¥å¿—
        archived = self.archive_old_logs(days=30)
        results['archived_logs'] = archived
        
        # 2. å‹ç¼©æ•°æ®åº“
        vacuum_result = self.vacuum_database()
        results['vacuum'] = vacuum_result
        
        # 3. åˆ†æç»Ÿè®¡
        stats = self.analyze_database()
        results['stats'] = stats
        
        logger.info("âœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆ")
        
        return results


# åˆ›å»ºå…¨å±€å®ä¾‹
database_optimizer = DatabaseOptimizer()
