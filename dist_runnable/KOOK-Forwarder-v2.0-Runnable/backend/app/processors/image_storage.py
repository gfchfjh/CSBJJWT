"""
å›¾ç‰‡å­˜å‚¨ç®¡ç†æ¨¡å—
ä»image.pyæ‹†åˆ†å‡ºæ¥ï¼Œä¸“æ³¨äºå›¾ç‰‡å­˜å‚¨ã€Tokenç®¡ç†å’Œæ¸…ç†
"""
import hashlib
import time
from pathlib import Path
from typing import Dict, Any, Optional
from ..config import settings
from ..utils.structured_logger import logger
from ..utils.metrics import metrics


class ImageStorage:
    """å›¾ç‰‡å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self):
        # å›¾ç‰‡å­˜å‚¨ç›®å½•
        self.storage_path = Path(settings.data_dir) / "images"
        self.storage_path.mkdir(parents=True, exist_ok=True)
        
        # Tokenæ˜ å°„ï¼ˆæ–‡ä»¶è·¯å¾„ -> Tokenä¿¡æ¯ï¼‰
        self.url_tokens: Dict[str, Dict[str, Any]] = {}
        
        # Tokenæœ‰æ•ˆæœŸï¼ˆé»˜è®¤2å°æ—¶ï¼‰
        self.token_ttl = 7200
    
    def save_to_local(self, image_data: bytes, filename: Optional[str] = None) -> str:
        """
        ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°
        
        Args:
            image_data: å›¾ç‰‡æ•°æ®
            filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨hashï¼‰
            
        Returns:
            æ–‡ä»¶è·¯å¾„
        """
        try:
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨MD5 hashï¼‰
            if not filename:
                file_hash = hashlib.md5(image_data).hexdigest()
                filename = f"{file_hash}.jpg"
            
            # ä¿å­˜æ–‡ä»¶
            filepath = self.storage_path / filename
            with open(filepath, 'wb') as f:
                f.write(image_data)
            
            logger.info(f"å›¾ç‰‡ä¿å­˜æˆåŠŸ: {filepath}")
            
            # æ›´æ–°å­˜å‚¨å¤§å°æŒ‡æ ‡
            self._update_storage_metrics()
            
            return str(filepath)
            
        except Exception as e:
            logger.error(f"å›¾ç‰‡ä¿å­˜å¤±è´¥: {str(e)}")
            raise
    
    def generate_url(self, filepath: str, expire_hours: int = 2) -> str:
        """
        ç”Ÿæˆå›¾ç‰‡è®¿é—®URLï¼ˆå¸¦Tokenï¼‰
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            expire_hours: è¿‡æœŸæ—¶é—´ï¼ˆå°æ—¶ï¼‰
            
        Returns:
            è®¿é—®URL
        """
        # ç”ŸæˆéšæœºToken
        token = hashlib.sha256(f"{filepath}{time.time()}".encode()).hexdigest()[:16]
        
        # ä¿å­˜Tokenæ˜ å°„
        self.url_tokens[filepath] = {
            'token': token,
            'expire_at': time.time() + (expire_hours * 3600)
        }
        
        # ç”ŸæˆURL
        filename = Path(filepath).name
        url = f"http://localhost:{settings.image_server_port}/images/{filename}?token={token}"
        
        metrics.record_image_operation('generate_url', 'success')
        
        return url
    
    def verify_token(self, filepath: str, token: str) -> bool:
        """
        éªŒè¯Tokenæ˜¯å¦æœ‰æ•ˆ
        
        Args:
            filepath: æ–‡ä»¶è·¯å¾„
            token: Tokenå­—ç¬¦ä¸²
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        if filepath not in self.url_tokens:
            return False
        
        token_info = self.url_tokens[filepath]
        
        # æ£€æŸ¥Tokenæ˜¯å¦åŒ¹é…
        if token_info['token'] != token:
            logger.warning(f"Tokenä¸åŒ¹é…: {filepath}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
        if time.time() > token_info['expire_at']:
            logger.info(f"Tokenå·²è¿‡æœŸ: {filepath}")
            del self.url_tokens[filepath]
            return False
        
        return True
    
    def get_storage_info(self) -> Dict[str, Any]:
        """
        è·å–è¯¦ç»†çš„å­˜å‚¨ä¿¡æ¯
        
        Returns:
            å­˜å‚¨ä¿¡æ¯å­—å…¸
        """
        total_size = 0
        file_count = 0
        oldest_file_time = None
        newest_file_time = None
        
        for filepath in self.storage_path.glob("*.jpg"):
            stat = filepath.stat()
            total_size += stat.st_size
            file_count += 1
            
            # è®°å½•æœ€æ—§å’Œæœ€æ–°æ–‡ä»¶æ—¶é—´
            if oldest_file_time is None or stat.st_mtime < oldest_file_time:
                oldest_file_time = stat.st_mtime
            if newest_file_time is None or stat.st_mtime > newest_file_time:
                newest_file_time = stat.st_mtime
        
        size_gb = total_size / (1024 ** 3)
        max_size_gb = settings.image_max_size_gb
        usage_percent = (size_gb / max_size_gb * 100) if max_size_gb > 0 else 0
        
        return {
            'total_size_bytes': total_size,
            'total_size_mb': total_size / (1024 * 1024),
            'total_size_gb': size_gb,
            'file_count': file_count,
            'max_size_gb': max_size_gb,
            'usage_percent': round(usage_percent, 2),
            'is_full': size_gb >= max_size_gb,
            'oldest_file_time': oldest_file_time,
            'newest_file_time': newest_file_time,
            'storage_path': str(self.storage_path)
        }
    
    def _update_storage_metrics(self):
        """æ›´æ–°Prometheuså­˜å‚¨æŒ‡æ ‡"""
        try:
            info = self.get_storage_info()
            metrics.update_image_storage_size(info['total_size_bytes'])
        except:
            pass
    
    async def cleanup_old_images(self, days: int = 7) -> Dict[str, Any]:
        """
        æ¸…ç†æ—§å›¾ç‰‡
        
        Args:
            days: ä¿ç•™å¤©æ•°
            
        Returns:
            æ¸…ç†ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            current_time = time.time()
            deleted_count = 0
            freed_space = 0
            
            for filepath in self.storage_path.glob("*.jpg"):
                # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´
                mtime = filepath.stat().st_mtime
                age_days = (current_time - mtime) / (24 * 3600)
                
                if age_days > days:
                    # è·å–æ–‡ä»¶å¤§å°
                    file_size = filepath.stat().st_size
                    
                    # åˆ é™¤æ–‡ä»¶
                    filepath.unlink()
                    deleted_count += 1
                    freed_space += file_size
                    
                    # åˆ é™¤Tokenæ˜ å°„
                    filepath_str = str(filepath)
                    if filepath_str in self.url_tokens:
                        del self.url_tokens[filepath_str]
            
            freed_mb = freed_space / (1024 * 1024)
            logger.info(f"æ¸…ç†æ—§å›¾ç‰‡å®Œæˆ: åˆ é™¤ {deleted_count} ä¸ªæ–‡ä»¶, é‡Šæ”¾ {freed_mb:.2f}MB ç©ºé—´")
            
            # æ›´æ–°æŒ‡æ ‡
            self._update_storage_metrics()
            
            return {
                'deleted_count': deleted_count,
                'freed_space_mb': freed_mb,
                'freed_space_gb': freed_mb / 1024
            }
            
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§å›¾ç‰‡å¤±è´¥: {str(e)}")
            return {
                'deleted_count': 0,
                'freed_space_mb': 0,
                'freed_space_gb': 0,
                'error': str(e)
            }
    
    async def cleanup_expired_tokens(self):
        """æ¸…ç†è¿‡æœŸTokenï¼ˆåå°ä»»åŠ¡ï¼‰"""
        current_time = time.time()
        expired_keys = []
        
        for filepath, token_info in list(self.url_tokens.items()):
            if token_info['expire_at'] < current_time:
                expired_keys.append(filepath)
        
        for key in expired_keys:
            del self.url_tokens[key]
        
        if expired_keys:
            logger.info(f"ğŸ§¹ æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸTokenï¼Œå‰©ä½™ {len(self.url_tokens)} ä¸ªæœ‰æ•ˆToken")
    
    def get_token_stats(self) -> Dict[str, Any]:
        """è·å–Tokenç»Ÿè®¡ä¿¡æ¯"""
        current_time = time.time()
        total_tokens = len(self.url_tokens)
        expired_tokens = 0
        valid_tokens = 0
        
        for token_info in self.url_tokens.values():
            if current_time > token_info['expire_at']:
                expired_tokens += 1
            else:
                valid_tokens += 1
        
        return {
            'total_tokens': total_tokens,
            'valid_tokens': valid_tokens,
            'expired_tokens': expired_tokens
        }


# åˆ›å»ºå…¨å±€å­˜å‚¨ç®¡ç†å™¨å®ä¾‹
storage = ImageStorage()
